[
    {
        "url":"https:\/\/www.spectroscopyonline.com\/view\/after-hurricane-spectroscopist-starts-over-leaving-dreams-behind-puerto-rico",
        "text":"After Hurricane, a Spectroscopist Starts Over, Leaving Dreams Behind in Puerto Rico\n\nFebruary 15, 2019\n\nIn the fall of 2017, Belinda Pastrana, like many Puerto Ricans, faced destruction all around her following of Hurricane Maria\u2019s arrival on September 20.\n\nIn the fall of 2017, Belinda Pastrana, like many Puerto Ricans, faced destruction all around her following Hurricane Maria\u2019s arrival on September 20. A few months later, Pastrana, a professor of biochemistry and biophysics at the University of Puerto Rico Mayaguez (UPRM), had relocated to Boston and was reviving her biotech company. Within a year, she was presenting new data on her company\u2019s analytical techniques at the SciX conference.\n\nPastrana and her company are rolling again. But all her work to build scientific programs and opportunity on her native island, and her dreams of expanding that for future generations, face an uncertain future.\n\nA Puerto Rican Returnee\n\nWhen Pastrana was young, like many talented Puerto Ricans, she left the island for graduate school. She completed her PhD in biophysical chemistry at Rutgers University, then began postdoctoral research at the Mayo Clinic & Foundation in Minnesota. Opportunities in the mainland United States were plentiful.\n\nBut she and her new husband, an organic chemist, dreamed of going back. \u201cMy husband and I both wanted to return to Puerto Rico what Puerto Rico had invested in us,\u201d she said. So in 1996, they both accepted offers for academic positions in the chemistry department at UPRM- taking a rare opportunity for two married scientists to land tenure-track professorships at the same institution.\n\nOver the years, Pastrana conducted her research, founded a biotech company, taught, and looked for ways to foster science on the island. One way she felt she could create more opportunities for talented local students was to develop a PhD program in applied chemistry. The program she and her colleagues created was rigorous: Students had to publish two peer-reviewed manuscripts\u00a0 as first author, in addition to completing their theses. They had to complete a practicum in an academic, industry, or government laboratory, with an original proposal written and defended by the graduate candidate. They also had two complete two electives in business administration.\n\nShe also focused on options for her undergraduates. Given the strong presence of the pharmaceutical industry in Puerto Rico, Pastrana emphasized preparing those students to work in pharmaceutical\u00a0 development, continue graduate studies in the United States, or pursue\u00a0\u00a0 a medical degree-all viable options for the more than\u00a0\u00a0 250 talented young people who graduated with chemistry, biology, chemical engineering, and biotechnology degrees during Pastrana\u2019s 20-year span as a faculty member.\n\n\u201cI wanted to show the world that excellent science could be done on the island, both basic and applied research, with the potential to have a direct impact on the quality of life of patients,\u201d she said.\n\nAfter the Hurricane\n\nAfter Hurricane Maria, everything changed. The devastation of this hurricane was far beyond that of previous storms.\n\nThe impact on the island as a whole has been well documented. What has been less discussed is the impact on science on the island. Pastrana\u2019s laboratories at UPRM fared better than many others, but much of the sensitive equipment was severely damaged or destroyed. The building\u2019s diesel generator had no fuel, because the priority was to send diesel fuel to clinics and hospitals. Other laboratories suffered greater damage. In particular, the lack of\u00a0 power\u00a0 or fuel for generators meant a lack of air conditioning in a hot climate and high humidity conditions, leading to mold growth everywhere. Mold destroyed scientific equipment, and in many cases, made classrooms, laboratories, and equipment unsafe. Her colleague, Samuel P. Hern\u00e1ndez, a chemistry professor, saw his laboratories largely destroyed.\n\nThe losses to her company, Protein Dynamic Solutions, Inc., which she had founded in 2011, were also significant. The company\u2019s work is focused on technology Pastrana developed to evaluate critical quality attributes of biopharmaceuticals, using quantum cascade laser microscopy, two-dimensional infrared correlation, and co-distribution analysis software to allow direct visualization of aggregates, map the regions prone to aggregation within the protein, and assess domain stability, concerns that affect drug safety and efficacy. But the backup power systems in place, all at sea level, failed. Much of her scientific instrumentation and supporting systems-such as freezers-were without power, resulting in significant losses of dedicated and original biological materials including clones, 5.3 kg of cells harvested from microbial expression, and purified recombinant proteins. These recombinant proteins were essential to her research and development efforts.\n\n\nBut Pastrana was most concerned about how the situation would affect her students\u2019 ability to complete their degrees. The university reopened after a month, and even though the disruption was significant, she knew her undergraduate students would be able to finish, and they did. Since then, of her eight seniors, five were accepted into medical school at the University of Puerto Rico Medical Sciences, one was accepted into the structural biology program at Yale University, one was accepted for graduate studies in immunology at Harvard, and one re-located to Boston to continue working at Protein Dynamic Solutions and will pursue graduate studies while in Boston.\n\n\nBut her four graduate students were a bigger concern. Through her network, she arranged for her two PhD students to finish their projects at other institutions: one at Vanderbilt University in Tennessee, and another at the Hauptman-Woodward Medical Research Institute in Buffalo. They defended their theses in July 2018 in the Biophysics Division of the Applied Chemistry program at UPRM. These PhD graduates are now doing post-doctoral research in the Walter Chazin\u2019s Laboratory at Vanderbilt.\n\nTwo more students were in the pipeline toward their PhD degrees and finished their course work during that extended semester of the hurricane. They decided to work or intern at the biopharmaceutical company Eli Lilly del Caribe, a branch of Eli Lilly located on the island, which had its own power station and continued to be operational after the storm. To date, one has decided to continue working at Lilly, and the second transferred to UPR Medical Sciences to continue her PhD.\n\nPastrana stopped taking in any more students, took a sabbatical leave without pay, and moved to Boston.\n\nRebuilding the Company\n\nBoston, she knew, had a good ecosystem for her business, offering access to biopharmaceutical companies and clinical research and development organizations. Indeed, the company is doing well. It is conducting protein aggregation analyses for several companies and has received continued non-dilutive funding from the National Science Foundation, including Small Business Innovation Research (SBIR) phase IIB funding. The company also has active collaborations with the National Institute of Standards and Technology (NIST) and the National Cancer Institute (NCI).\n\nThe Long Term\n\nIn the meantime, the family is split into two locations. Her older son came with her to Boston, to get ready to apply for graduate school. But her husband, a tenured faculty member at UPRM, stayed on the island to be near his elderly mother, and the couple\u2019s younger son stayed with his dad.\n\nThe couple knows they can sort out a long-term plan for themselves. But Pastrana\u2019s dreams of continuing the development of science and scientists on the island are uncertain.\n\nShe had built her laboratories there through 20 years of grantsmanship, replacing equipment after previous hurricanes through insurance and by writing new grant proposals to fund what the insurance didn\u2019t cover. Over that same period, she graduated 250 undergraduate students (96% of whom continued their graduate studies in the United States) and 11 MS students in biophysics. She was recognized as a Henry Dreyfus Teacher Scholar. She developed a doctoral program and her first two PhD students have graduated, in spite of the storm.\n\nBut now the future of all that effort is in doubt. The island\u2019s difficult recovery is exacerbated by the poor economic situation there. And with climate change, the likelihood of more strong hurricanes seems high.\n\nWill Pastrana return to Puerto Rico? \u201cIt\u2019s not a decision I am ready to make,\u201d she said.",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9139658809,
        "format_confidence":0.8067215681
    },
    {
        "url":"https:\/\/www.nationalobserver.com\/comment\/49477",
        "text":"Something has changed this summer, in Canada, and throughout the world. Across social and traditional media, there's a new face of summer emerging.\n\nGone are the typical images you're used to seeing of people swimming, camping and hiking. Instead, all you see are disturbing images of smoke, flames and family picnics held against a backdrop of grey skies full of falling ash.\n\nThe extraction economy is an extinction economy, or maybe more accurately an extinction machine, writes @popejulia It has always burnt everything in its path. #wildfires #climatechange\n\nIn place of the celebratory nature-revelling the season usually brings are expressions of fear and grief at the idea that we may have abruptly stepped into a new kind of summer: summer as a season of fire and destruction in a world out of balance.\n\nMy heart breaks seeing images where day is as black as night in parts of British Columbia from the soot of the forests on fire. As we watch them burn, I remember when I felt this heartbreak for the first time: I was in my teens, witnessing the destruction wrought by the mountain pine beetle in the forests of the B.C. interior where I grew up.\n\nThis humble little insect, fueled by warmer winters, turned entire forests as far as the eye could see into red, dead, standing monuments to climate change.\n\nBack then, we responded to this ecological crisis by extracting the trees more aggressively than ever. \u201cWaste-wood salvaging\u201d became an excuse to let logging companies consume much of what was left of the forest. We burned the wood \u201cwaste\u201d (woody debris the logging companies didn\u2019t want to process and didn\u2019t care to leave to become new soil) in giant piles that stretched for miles. These fires lit up the skies in the fall after the urban environmentalists had returned from their summer vacations. We did this beside old clearcuts, creating \u201cbig openings\u201d \u2014 harvested, devastated landscapes of larger than 100,000 hectares throughout the north.\n\nA picture of a 600-hectare portion of forest, included in a 2009 report, is marked up to show dates of harvest. Illustration provided by the B.C. Forest Practices Board\nA picture of a 600-hectare portion of forest, included in a 2009 report, is marked up to show dates of harvest. Illustration provided by the B.C. Forest Practices Board\n\nSeeing these in person was devastating and shocking beyond words. It was like looking under the hood of our economic system expecting to find a sophisticated, modern engine and finding instead a violent, brutal monster that valued only what it could devour and turn into money. It had no word for \u201ctomorrow\u201d or \u201clife.\u201d And it was like looking into the future.\n\nBoom and bust cycles in the extraction economy have always brought incredible destruction and pain, especially to those closest to the land. Not by accident but by design \u2013 billions of dollars of wealth has been stripped from the land for the benefit of mostly outside investors who never intended a long term sustainable plan for rural or Indigenous communities, much less the ecosystems they rely on.\n\nBut with accelerating climate change, we now have boom, bust and burn (this burn has many forms, fire is just one). And it affects everyone.\n\nThe truth is this economic system has always been on fire. The terrifying object at the end of the extraction economy is the devastating and total incineration of almost everything we know and love. This is the only endgame in the extraction economy \u2014 it is what happens when a model dependent on infinite growth is played out on a planet with finite resources.\n\nThe extraction economy is an extinction economy, or maybe more accurately an extinction machine. It has always burnt everything in its path. That is what it\u2019s designed to do. The people and living things on the periphery have always felt it first.\n\nBut now in a world of global climate disruption, the match has burned down to our fingers. There is no periphery and no centre. Just one interconnected and interdependent world \u2013 on fire, together.\n\nIt is not a bad thing to see this laid bare. We need new models for a sustainable civilization, and this will be a big lift that will require change at every level of social organization. The shocks to our current system that arrive early are better than the ones that come too late.\n\nRight now, it is not hard to look around and see a world of excruciatingly painful gifts, waiting for us to receive them and do what is needed in response.\n\nThe grief that witnessing this produces in us is actually love \u2013 love under intense pressure to evolve. It\u2019s like a diamond, desperately trying to be born. Except these aren\u2019t diamonds, they are the seeds of a new system, and they can only germinate in the deepest part of the human heart. They get watered with our tears, but only grow through our committed actions.\n\nAs I watch the land that I love burn, I greet this grief in my heart and know how much love and hope it contains. And I think of the millions and millions of people who are all feeling this right now, together.\n\nThis is a heartbreaking and beautiful time to be alive, together.\n\nFires have always enriched the land, and fire is how land is made. And, fire ultimately transforms matter into only what fire can\u2019t take away.\n\nNow we get to see how fire transforms us.\n\nJulia Pope is the former strategic communications director of and Leadnow. Originally from Naramata, B.C., she now lives in Berkeley, California, and is the co-founder of Hylo: a web and mobile app that helps communities collaborate and create together.\n\nInvestigative journalism has never been more important. Will you help?\n\n\n\nNot much to quarrel with here.....its the model poor earth dependent people have experienced for a long time now. But wealthy cities are built on just such out of sight strip mining, and trying to imagine what we will do now that it appears we can't continue with 'business as usual' is hard.\n\nA growing right wing in Canada seems intent on continuing to whine about taxes. As if not paying for anything is going to keep us secure. I'm far from sure large segments of our population 'get' what these fires are telling us. They didn't get it last year, or the year before. And they don't seem to get it if its in Portugal, or Greece....\n\nHopefully the smokey fires will help. But it's very late in the afternoon to just be waking up. What alternatives can we imagine? Design together? Implement on a wide scale?\n\nToday's must read",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.5923778415,
        "format_confidence":0.7840274572
    },
    {
        "url":"http:\/\/www.bio-itworld.com\/BioIT_Article.aspx?id=97649",
        "text":"YouTube Facebook LinkedIn Google+ Twitter Xingrss \u00a0\n\nTesting Positive\n\nSabeti tags selection signatures in human populations.\n\nMarch 16, 2010 | Certain signs of trait selection among human populations are easy to recognize\u2014skin pigmentation, height, shape, and the ability to digest lactose are some examples.\n\nIn a superb paper published in Science, Pardis Sabeti and colleagues at Harvard University and the Broad Institute describe a powerful computational strategy for systematically searching across the human genome to pinpoint signatures of positive selection.\n\nSabeti\u2019s team has harnessed three complementary approaches that, when combined, highlight discrete regions that have undergone positive selection in human populations dating back some 30,000 years. By applying this \u201cComposite of Multiple Signals,\u201d or CMS approach, Sabeti\u2019s team dramatically refined genome regions under positive selection, typically narrowing the interval to just tens of kilobases\u2014a single gene\u2014and just a handful of putative variants.\n\nFinding Footprints\n\nIranian-born Sabeti, currently an assistant professor of organismic and evolutionary biology at Harvard University, has been working on methods to detect \u201cthe footprint of natural selection\u201d since she was a Rhodes Scholar.\n\nPositive natural selection is the means by which advantageous traits become more common in a given population, perhaps by increasing an individual\u2019s ability to adapt to shifting environmental conditions and\/or reproduce. Sabeti\u2019s interest is in understanding what factors have shaped human evolution, especially genes that may impart resistance to infectious diseases such as Lassa fever and malaria in Africa and other places.\n\nIn 2002, working with Eric Lander, Sabeti developed a long haplotype method that could detect such footprints. \u201cWhen [an] advantageous mutation arises in the population, it takes with it the entire [genomic] region around it,\u201d she explains. But the candidate regions were very large, typically spanning hundreds of thousands of bases and dozens of candidate genes. \u201cYou couldn\u2019t really make heads or tails of what was going on,\u201d she admits. Later, while working on\u00a0a review article for Science, Sabeti focused on the black box: \u201chow are you going to isolate what you care about?\u201d Of the five types of genomic patterns used by researchers to detect selection, three in particular were relevant to human population data (rather than, say, other species). In addition to her long haplotype method, the others were population differentiation and the derived allele effect.\n\nIn 2007,\u00a0Sabeti published a paper in Nature in which she proposed combining these various approaches. Analyzing data from the international haploytpe map (HapMap) project, she reported an intriguing hit in the Asian population\u2014a gene called EDAR, which governs hair, sweat gland and teeth formation.\n\nTriple Score\n\nSince setting up her lab as an assistant professor at Harvard\u2019s Center for Systems Biology, Sabeti has set about combining those three approaches to produce a formal statistical measure of positive selection. The CMS method applies three independent approaches to identity signatures of positive selection, as follows:\n\n  \u2022 Long Haplotype: This method tracks the age of a mutation using genetic recombination as a clock. \u201cYou can essentially track the age of the mutation by how much breakdown has occurred on that haplotype,\u201d says Sabeti. \u201cBy identifying outliers to the general pattern across the genome \u2013 a prevalent variant on a very long haplotype\u2014that\u2019s a signal selection.\u201d\n  \u2022 Derived Frequency. A spike in the frequency of the new, or derived, allele, because it generally takes a long time for a new mutation to spread in a population.\n  \u2022 Population Differentiation. \u201cIf you scan the genome and you see a place where there\u2019s a spike in a highly differentiated variant, that\u2019s another signal selection.\u201d The classic example is the Duffy blood group locus that protects against Plasmodium.\n\nWhile the long haplotype method is in some ways the most powerful, it lacks the refinement of the other two methods in localizing the signal. The actual causal variant will have all three signals, whereas surrounding variants will show little overlap.\n\n\u201cThe [CMS] test performed better than we ever expected, especially in the way it localizes spatially,\u201d says Sabeti. \u201cIt\u2019s able to distill the causal variant from the non\u2013causal variants, but what\u2019s beautiful about it is the breakdown of the correlation with the other variants is so rapid, you can localize to tens of kilobases.\u201d\n\nTime Signatures\n\nAfter performing simulations to test the CMS method, Sabeti\u2019s \u201cperfect grad students\u201d and co-first authors\u2014mathematician Sharon Grossman (daughter of Princeton economics professor Gene Grossman) and Russian computer scientist Ilya Shylakhter\u2014applied it to more than 180 regions of the human genome deemed to be under positive selection, initially containing some 1500 candidate genes. CMS whittled this down to 64 hotspot regions containing a single gene, 35 stretches containing multiple genes, and curiously, 79 genome regions apparently bereft of protein-coding genes.\n\nThe Harvard team found potentially interesting functional gene groupings, such as sensory perception genes enriched in East Asia, immune system genes in West Africa, and metabolism genes in all three populations, as well strong hits for several known skin and eye color genes. One of several sensory perception genes under selection in East Asia is protocadherin 15, which functions in hearing and vision\u2014the development of inner ear cells and maintenance of retinal photoreceptors. Its functional significance is unclear.\n\nAnother gene under selection in East Asia is the leptin receptor, which is linked to body mass index (BMI), blood pressure and obesity. \u201cThe [causal] mutation that we found is associated with an increased BMI, increased absorption of fat and nutrients. That suggests that 10,000 or 30,000 years ago, it was better to basically gain more weight,\u201d Sabeti suggests. Meanwhile, in West Africans, two genes, variants affecting the expression of two genes, PAWR and USF1, have come under selection, presumably linked to infectious disease.\n\nSabeti is still tweaking the CMS test, but reckons it\u2019s close to the theoretical limit. \u201cIt\u2019s very hard to distill just by population genetic data alone what is the causal variant.\u201d Sabeti is already extending CMS to sequence data from the 1000 Genomes Project, which will by definition contain the causal variant in any given region. But in many cases, pinning down the causal change will come down to functional investigation. There are also possibilities of extending the analysis further back in human history and to other species.\n\nThe software tools for CMS analysis are all homegrown, and should soon be available, perhaps wrapped into\u00a0a program called Sweep for the long haplotype analysis.\n\nThis article also appeared in the March-April 2010 issue of Bio-IT World Magazine.\nSubscriptions are free for qualifying individuals. Apply today.\n\nView Next Related Story\nClick here to login and leave a comment. \u00a0\n\n\nAdd Comment\n\nText Only 2000 character limit\n\nPage\u00a01\u00a0of\u00a01\n\nFor reprints and\/or copyright permission, please contact\u00a0 Terry Manning, 781.972.1349 ,",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9953731894,
        "format_confidence":0.6686826944
    },
    {
        "url":"http:\/\/thebuzzdiary.com\/the-history-of-plastic-use-its-dangerous-influence-on-climate-change-part-i\/",
        "text":"The History Of Plastic Use & Its Dangerous Influence On Climate Change \u2013 Part I\n\nThere is no living in denial about climate change anymore! It was around World War 2 in the USA that plastic became a fad, maybe because people were not prophesying survival of themselves, forget reasoning about the survival of the planet. The term \u2018consumer\u2019 emerged and disposable versions of everyday household objects took over markets all around the world steadily. Items built for the war effort got redirected to civilians. Plastic is one of the most universal materials in the economy and among the most steadfast pollutants on Earth causing climate change. The three decades- 50s to 70s witnessed a use and throw culture on a rise which now has resulted in panic across boundaries.\n\nHere is a vintage ad glorifying the freedom of throwaway and this was when the whole thing began-\n\nOver 25 State governments in India may have to pay environment compensation of \u20b91 crore each for not submitting their action plans on systematic disposal of plastic waste to the Central Pollution Control Board (CPCB) as the April 30 deadline set by the National Green Tribunal has expired long ago.\n\nExplaining the cause of non-compliance by State governments, NGO Indian Pollution Control Association (IPCA) Chairman Ashish Jain said there was lack of knowledge among State authorities and a communication gap between State and central government officials. He exclaims, \u201cWaste management is the last in the list of priorities of municipal corporations. The need to conduct awareness programs to educate state-level officials to carry out necessary measures to segregate plastic and dispose of it.\u201d\n\nOn Goa Statehood Day, Chief Minister Pramod Sawant on Wednesday swore that he would take the responsibility of treating waste generated in government offices, while also nominating three others, including the Leader of Opposition, to take similar responsibilities in a bid towards a \u2018Clean Goa, Green Goa\u2019. Addressing a press conference at his official residence, Mr. Sawant said that he would be setting up bio-digesters in all government offices to treat the waste while also urging citizens to set up similar bio-digester units at home.\n\nThe authors of the report by the Center for International Environmental Law, estimate the greenhouse gas footprint of plastic from the cradle to the grave for the first time. \u201cAt current levels, greenhouse gas emissions from the plastic lifecycle threaten the ability of the global community to keep global temperature rise below 1.5C,\u201d the report says. The authors also say disposable plastic found in packaging and fast-moving consumer goods forms the largest and fastest-growing segment of the plastic economy.\n\nCompanies are thinking that any alternative to plastic is better and this is a terrible mistake. With the petrochemical and plastic industries planning a massive expansion in production, the global pandemic seems never-ending. The challenges to them, however, are-\n\nNearly all plastic \u2013 99% \u2013 is made from fossil fuels.\n\nLife Cycle Assessment (LCA) and Product Carbon Footprint (PCF) assessments to determine objectively which is the best environmental packaging option, regardless of the material.\n\nStrategies focused on reducing the multilayer structures either by materials as compatible as possible from the point of view of recycling or by the use of coatings that can obtain good properties with less quantity of material.\n\nWaste management process in terms of collection, separation, and recycling to make the process both technically and financially viable. Incineration creates the most CO2 emissions among the plastic waste management methods.\n\nBy the end of 2015, 8.3bn metric tonnes of plastic had been produced \u2013 two-thirds of which has been released into the environment and remains there. Forty percent of plastic packaging waste is disposed of at sanitary landfills, 14% goes to incineration facilities and 14% is collected for recycling. But how well engineered is recycling in this era of climate change? Is plastic banned from the countries producing the most plastic pollution? Have we realized yet that climate change impacting wildlife around the world could endanger us humans and bring us to an end of the world?\n\n\nThe History Of Plastic Use & Its Dangerous Influence On Climate Change \u2013 Part II\n\nThis article has been contributed by SUBAH.\n\nSUBAH is an enabler of CSR rendering research and advisory services on CSR in India to industry, businesses and non-profit organizations. They enable alliances between organizations with corresponding social purposes and conduct research on CSR impact. With a mission to build an enduring and sustainable culture for a better tomorrow, Subah is assembling an ever-growing diverse community of conscious stakeholders, groups, & citizens. Connect with them at",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9834028482,
        "format_confidence":0.9366033077
    },
    {
        "url":"http:\/\/science.time.com\/2012\/04\/20\/two-years-after-the-gulf-oil-spill-why-we-wont-stop-drilling\/",
        "text":"\n\n  \u2022 Share\n  \u2022 Read Later\nAFP\/Getty Images\n\nThe 2010 Gulf of Mexico oil spill\n\nIt was two years ago today that the Deepwater Horizon\u2014a top-of-the-line offshore drilling rig owned by BP and run by Transocean\u2014experienced a sudden burst of gas from a three-mile long well its crew was drilling in the Gulf of Mexico, 40 miles south of the Louisiana coast. The combustible methane rushed up the well and into the rig, igniting a massive explosion that would kill 11 workers, destroy the Deepwater Horizon\u2014and trigger the biggest offshore oil spill the U.S. had ever seen.\n\n4.9 million barrels of oil would spill for nearly three months before the shattered Macondo well was finally capped. The oil spill dominated the news for much of the summer\u2014I wrote two cover stories on it for TIME, just a few weeks apart, and for most of the summer we discussed little else on this blog. It wasn\u2019t just the spectacle of the multi-billion dollar oil industry trying and repeatedly failing to close a blowout in conditions that were comparable to working on the moon, nor was it the simply the sight of pelicans, marshes and fishermen alike drenched in oil. The 2010 oil spill demanded our attention because it seemed to represent a potential turning point in our tortured relationship to crude oil. The usually invisible environmental cost was right there for everyone to see on BP\u2019s webcam, crude billowing up from the well\u2019s shattered pipes, oil turning the Louisiana marshes a dark chocolate brown.\n\nAs outraged as environmentalists were, they saw the oil spill as an oppourtunity. The Santa Barbara blowout of 1969 had helped kickstart the green movement and ensure that offshore drilling wouldn\u2019t be expanded on the Atlantic or Pacific Coasts. Surely a far bigger spill, in a much more media-intensive moment, would help convince Americans to block new oil offshore production in the Gulf or Alaska, and cement support for renewable forms of energy that are pretty much incapable of spilling?\n\nAnd yet, two years on, the big story about American oil is how much of it there suddenly is. Thanks largely to a boom in tight oil in North Dakota and Texas, domestic oil production reversed a decades-long slide, and the talk now isn\u2019t about getting of oil, but in becoming energy independent. Concern about the oil spill has given way to complaints about high gas prices. The oil industry itself\u2014which rarely mentions the spill\u2014continues to push for drilling in more offshore territory, from the eastern Gulf to the cold waters of Arctic Alaska. And for the most part, the Obama Administration seems happy to see that drilling go forward. What happened?\n\n(MORE: The Gulf Oil Spill)\n\nIn short, oil won. It was never realistic to think that the Gulf oil spill would somehow lead to an end to offshore drilling in the U.S.\u2014especially since, without a corresponding drop in consumption, we\u2019d just end up importing more oil from international sources. (And some of those sources would be far worse for the environment than the disaster in the Gulf\u2014Nigeria, a major exporter to the U.S., experiences a cumulative Exxon\u00a0Valdez-sized spill each year.) Over at\u00a0Climate Central, Michael Lemonick (who also contributes to TIME) notes that even with oil consumption falling in the U.S. thanks to a still-slugging economy and more fuel-efficient vehicles, oil is still the oxygen of American economic life, and one no President will seriously attempt to stifle:\n\nThe fact that gasoline is pushing $4 a gallon in an election year could be a factor \u2014 just as politics is plausibly a factor in the administration\u2019s announcement last fall that it would encourage \u201crobust oil and gas development\u201d in the Gulf starting this year, and why the president included oil drilling as part of the \u201call-of-the-above\u201d energy strategy\u00a0he outlined\u00a0in this year\u2019s State of the Union address.\n\nIt\u2019s hardly just politics, though. It\u2019s the fact that our economy has evolved to be dependent on road transportation, especially since the 1950\u2019s. True, Americans have beendriving less lately, thanks to the recession and high gasoline prices. The trend is stronger among young people, according to a\u00a0new report. But since the population is still growing, the prospects of reducing our oil consumption drastically are pretty remote at this point.\n\nIndeed, despite the arguments of his critics, Obama has hardly been anti-oil. But even if the oil spill has done little to slow the general expansion of drilling, at the very least it should have helped make drilling safer. Investigations in the wake of the spill showed countless problems with the oversight of offshore drilling and the response to a major spill\u2014remember the BP oil spill plan that listed the very cold-weather walrus as a native species of the Gulf\u2014was calamitous, especially in the early days. The very fact that it took nearly three months to cap the deepwater well indicated that there were risks to offshore drilling\u2014especially in the deep\u2014that the industry and the rest of us hadn\u2019t reckoned.\n\n(MORE: There Will Be Oil\u2014and That\u2019s the Problem)\n\nThere were safety improvements in the wake of the spill. The much-criticized deepwater moratorium gave the government time to rejigger offshore oversight, giving birth to the awkwardly named but generally better Bureau of Ocean Energy Management, Regulation and Enforcement (BOEMRE). A presidential commission issued a report nearly a year after the spill that was scathing in its indictment of regulatory and industry failures, but offered a blueprint for better drilling. The oil industry itself\u2014taking a page from the nuclear industry after Three Mile Island\u2014created the Center for Offshore Safety, and announced plans to develop a third-party audit process for drilling.\n\nBut that same Presidential commission has just taken another look at the state of offshore drilling and the response to the oil spill\u2014and it\u2019s far from positive. You can download a PDF of the report here, but Donald Boesch\u2014president of the University of Maryland Center for Environmental Science and a member of the commission\u2014has already written about his concerns in\u00a0Nature:\n\nCement formulation, testing and placement \u2014 major factors in the blowout \u2014 seem to be more of an art than a science. Cementing is also central to debates on the increased recovery of hydrocarbons by hydro-fracturing, because it is critical both to limiting fugitive emissions of methane and to preventing contamination of shallower aquifers.\n\nThe 2010 accident showed that no operating company in the world had the capacity to rapidly contain a deep-water blowout. It took months of seat-of-the-pants engineering to build and deploy a capping stack that provided effective containment. Confusion reigned over the fate of the oil and gas released 1,500 metres below the surface, largely because of a lack of understanding of the operating environment, including the direction and speed of water currents, and the behaviour of hydrocarbons released at depth.\n\nAnd Boesch reserved particular contempt for the near total failure of Congress to do much of anything in the wake of the oil spill, other than grandstand:\n\nUnfortunately, the US Congress \u2014 caught up in partisan rancour, including debates about expanding offshore oil drilling \u2014 has failed to adopt legislation to address the lessons learned and the recommendations of the oil-spill commission and others. Such legislation should codify the executive reforms mentioned earlier into law, increase liability limits, and dedicate sustained funding for oil-spill research and environmental assessment and monitoring.\n\nEven in the current constrained fiscal circumstances, improved oversight and essential R&D could be supported by industry fees amounting to pennies per barrel, imperceptible within the daily fluctuations in price on the world market or at the pump.\n\nUnfortunately attempts by Congress to tighten regulation of offshore drilling\u2014especially in the new area of the Arctic, where conditions will be far more treacherous than those experienced in the Gulf\u2014are often tripped up over disagreements about revenue sharing. (The states where drilling occurs, like Alaska, want to keep most of the money, while other states want more kicked back to the federal government.) Drilling can\u2019t be made perfectly safe, but it can be made safer\u2014and if we\u2019re going to let rigs cruise the icy seas of the Arctic, or the coastal waters off states like Florida or Maine, it must be made safer. That\u2019s the only opportunity left to be made of the 2010 oil spill, as it recedes further and further from memory.\n\nMORE:\u00a0Nearly Two Years On, Did the BP Oil Spill Have to Happen to BP?",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.6557144523,
        "format_confidence":0.9721431732
    },
    {
        "url":"http:\/\/niazi-pharmaceuticalinfo.blogspot.de\/2009\/08\/challenges-in-biopharma-contamination.html",
        "text":"Friday, August 7, 2009\n\nChallenges in biopharma contamination control\n\nKeep It Clean\n\nKeep It Clean\n\nIn June, biotech giant Genzyme was forced to temporarily shut down its plant in Allston, Mass., when a virus was discovered in one of the plant\u2019s six bioreactors. Genzyme said that although the virus could not infect humans, it could impede cell growth and slow production of the drugs manufactured there\u2014Fabrazyme (agalsidase beta), which treats Fabry disease, and Cerezyme (imiglucerase), a therapy for Gaucher disease. The production suspension meant temporary rationing of the drugs, with patients asked to skip doses.\n\nThe suspension was projected to last until the end of July, and the rationing left patients taking the drugs\u2014about 8,000 worldwide\u2014worried about how they would get treatment. Other companies hurried to fill the gap; Shire PLC filed a new drug application with the Food and Drug Administration (FDA) for its Gaucher drug, velaglucerase alfa, under a treatment protocol that would allow the company to market the drug before approval, requiring that it be initially provided free of charge.\n\nMeanwhile, Genzyme was expected to lose between $100 and $300 million in manufacturing revenues as a result of the shutdown. This was actually the second time the virus\u2014called Vesivirus 2117\u2014had hit Genzyme\u2019s production facility; the first incident occurred in 2008 and caused declines in cell productivity. The 2009 contamination was detected by Genzyme\u2019s own monitoring system; the company had recently developed a highly specific assay for Vesivirus.\n\nLessons Learned\n\nThe Genzyme incident underscores the importance of contamination control and monitoring in the biopharmaceutical industry, said Ken Christie, senior director of consulting services for VTS Consultants Inc. \u201cBiopharmaceuticals are primarily sterile products by nature, and anything labeled a sterile drug is something that the FDA, or any European regulatory agency, is going to see as possessing the highest level of risk to the public. As a result, the control of potential sources of contamination becomes of primary importance. Because biopharmaceutical companies are growing cells and working with reactor processes, the challenges are even greater.\u201d\n\nMultiple elements must work effectively together to ensure good contamination control, said Christie. They include:\n\n  \u2022 facility and equipment design;\n  \u2022 environmental systems;\n  \u2022 maintenance;\n  \u2022 personnel;\n  \u2022 monitoring; and\n  \u2022 cleanup.\n\nOf these areas, the facility and equipment design element remains one of the most significant challenges for biopharmaceutical companies today, according to Rebecca Brewer, director, consultancy services, validation and GMP compliance with Dober Group. \u201cThe reactor design is significantly more complex than in traditional pharma, and the bioreactors, in particular, become challenging if the cleaning-in-place (CIP) and sterilization-in-place (SIP) systems have not been designed to properly access and provide cleaning to all surfaces.\u201d\n\nThat happens fairly often, Brewer said, because of the complexity of the equipment. People who design bioreactors are not experts in CIP, and people who design CIP are not experts in bioreactors. And they talk to each other, she said, \u201cless often than you would hope.\u201d\n\nThere\u2019s no such thing as a perfectly cleanable system unless it\u2019s \u201can empty tank with no features in it,\u201d Brewer said. \u201cBaffles, dip tubes, bottom-mount agitators\u2014reactors have all sorts of things that make them difficult to clean,\u201d she explained. \u201cBecause of the conditions that the product sees during processing, including heat or foam generation, there are difficult-to-remove soils in challenging locations.\u201d\n\nBiotech facilities today are seeking to augment CIP design by modifying factors such as spray ball type or spray ball position, or by changing them entirely. \u201cIn cases where more simple engineering fixes can\u2019t be accomplished, you end up having to augment CIP with additional manual cleaning, which is never anybody\u2019s favorite,\u201d said Brewer. \u201cIf you can\u2019t overcome a shadowed area or a blind spot, you\u2019re left with very few choices in terms of how to manage it. But if you don\u2019t look after those issues, you will develop buildup in [the] system, with contamination potentially spoiling batch after batch of product.\u201d\n\nBrewer suggested that the best approach to CIP design involves due diligence during engineering of the system, testing for coverage as it\u2019s designed and built. \u201cTypical coverage testing tests one spray device or one flow circuit at a time. And in the real world, to optimize the cleaning cycle, people want two or three fluid paths on at the same time. If you\u2019re going to do that, you need to be sure that\u2019s how they did the original testing, in order to get coverage without interference of one flow with another or cancellation of spray from having them strike each other in the middle of the vessel and miss their target.\u201d\n\nOn the left is a cluster of six calciviruses (genus vesivirus), the type of virus that recently caused contamination at a Genzyme plant. On the right is a magnified view of the surface of a single vesivirus obtained using cryomicroscopy and having a resolution of about 20 angstroms. (Source: Al Smith, PhD)\nSource: Al Smith, PhD\nOn the left is a cluster of six calciviruses (genus vesivirus), the type of virus that recently caused contamination at a Genzyme plant. On the right is a magnified view of the surface of a single vesivirus obtained using cryomicroscopy and having a resolution of about 20 angstroms.\n\nCleaning, Sterilization Interface\n\nThe interface between cleaning and sterilization is also important. \u201cIf you have a microbiological contaminant in the system, biotech firms find it very difficult to eradicate it once it\u2019s taken hold and perhaps formed a biofilm,\u201d Brewer said. \u201cSome of this may be due to construction and CIP issues and some due to inadequate SIP to conquer the problem after a CIP process has left residue behind. You have to look at CIP and SIP as partners in the same goal\u2014microbiological cleanliness.\u201d\n\nAnother key challenge to maintaining a sterile environment in a biotech facility is the very people who run it. \u201cYou can build a facility and put in systems that would give you a \u2018cleanroom\u2019 environment, but once you bring operators into that picture, the potential for contamination doubles. People are the biggest source of contamination,\u201d said Christie. That\u2019s where design of the facility itself comes in\u2014systems literally have to be protected from their operators.\n\nThe FDA prefers isolator technologies when possible and, when not, restricted access barrier systems (RABS). Barrier isolators enclose the system and do not require a separate cleanroom, while RABS systems must be placed in a cleanroom. They cost less than isolators and appear to achieve the same results, but the agency does indicate a general preference for isolators.\n\n\u201cAll of these types of systems are designed to minimize the amount of interaction that an operator has around the critical areas of where a product is filled and stoppered,\u201d Christie explained. \u201cThey restrict an operator\u2019s interactions around the critical step where an open vial or syringe or plastic bottle is.\u201d\n\nIsolators and RABS have been around for quite some time, but recently their designs have become more efficient and better able to accommodate a variety of sizes in the filling lines they can encase. \u201cYou can have a small company down the road that may need to only fill several hundred vials for a clinical study, while larger companies will have lot sizes of hundreds of thousands of vials at a time,\u201d said Christie. \u201cBecause of that, the overall size of the filling line gets to be rather large, and companies are coming up with much more efficient design, with access to motors and things that might break without jeopardizing the cleanroom environment in which these things are placed.\u201d\n\nA current RABS design, for example, allows access to the motorized components of the filling unit from the outside wall of the cleanroom. \u201cThis way, an electrician or mechanic does not have to go into the clean area and open the machine,\u201d Christie said. \u201cAll access is from the wall on the non-controlled side of the equipment, so the environment where the filling actually occurs is not jeopardized. That\u2019s involved in a lot of the new designs.\u201d\n\n\ufeffIf you have a microbiological contaminant in the system, biotech firms find it very difficult to eradicate it once it\u2019s taken hold and perhaps formed a biofilm.\n\u2014Rebecca Brewer, Dober Group\n\nMicrobe Messes\n\nAlthough the bane of Genzyme\u2019s existence these days is a virus, many biotech facilities struggle with prevention, control, and cleanup of molds, according to Jim Polarine, a technical services specialist at STERIS Corporation who focuses on microbial control in cleanrooms and other critical environments.\n\n\u201cI was brought into a site in California where they had such a problem with molds that it got into the stainless steel and ductwork in the cleanroom, and they had to spend about $200 million to replace the stainless steel and the flooring,\u201d he said. \u201cBy the time I got called in, contamination was running rampant. We tried all the usual chemistries and they could control it for a while, but they had let things get out of hand and the mold was innately in the surfaces. When it gets into the flooring and up into the gaskets of the HEPA filter, then you have a big problem.\u201d\n\nAt another facility, this one in Boston, an operator dropped a glycol tube, which broke on the floor. Growing in the tube was a spore-forming bacterium called Bacillus polymyxa. \u201cHe tracked it all through the cleanroom and the entire biotech site, and it ended up getting into the product, on the walls, and on the floor,\u201d Polarine said. \u201cNeedless to say, it became a very long, drawn out process.\u201d\n\nSTERIS most often uses a liquid cold disinfectant called Spor-Klenz, a stabilized blend of peracetic acid, hy... (truncated)",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.7943718433,
        "format_confidence":0.8087666631
    },
    {
        "url":"http:\/\/complexitylabs.io\/sustainable-development-decoupling\/",
        "text":"\u201cThe search for sustainable development becomes a search for an adequate mode of civilization in the 21st Century\u201d \u2013 Dr. Paul Raskin\n\nSustainable Development\n\nThe 20th Century, driven by scientific and technological advances, was a time of remarkable change for human civilization. But it was also a century when the extraction of many natural resources began for the first time in history to follow an essentially exponential growth path. The extraction of construction materials grew by a factor of 34, ores and minerals by a factor of 27, fossil fuels by a factor of 12, and biomass by a factor of 3.6. As we all know exponential growth or decay of any kind spells one thing, unsustainability.\n\nSustainable development can be identified as the central challenge of the 21st Century, one that crosses all domains. Sustainable development is typically understood with reference to the future availability of resources. A typical definition of sustainable development would read something like this; sustainable economic growth is economic development that attempts to satisfy the needs of humans but in a manner that sustains natural resources and the environment for future generations. Sustainable economic growth is managing these resources in a manner that they will not be depleted and will remain available for future generations.\n\nBut this interpretation of sustainability is really quite a limited definition, it simply tells us about the outcomes of sustainable or unstainable activity. It does not tell us about the actual dynamics at play that make a system more or less sustainable, which is really what is needed to make the concept more concrete. In the language of systems theory, sustainability is more about the relationship between a system and its environment. It is a function of the rate and volume of resources consumed and the level of negative externalities produced by the system. The faster and more it consumes the environment\u2019s resources and the more negative externalities it exports back to the environment, the less sustainable it can be said to be. This is a function of the size of the economy \u2013 how many people are there and how much do they consume \u2013 but just as importantly the degree of efficiency to those economic processes.\n\nOur global economy is developing rapidly whether we like it or not, billions more people will be added to the plant in the coming decades and billions more will move up into the middle class to demand more resources. This economic development offers many benefits to those in developing economies, significantly improving their quality of life as it delivers, education, basic health care, clean water, food, recreation etc. These are things that we can not deny to anyone, but how then do we square the circle, between demanding more to fuel this development and the limits of natural ecosystems.\n\nThe question is how do we grow an economy while having less impact and this really means two things, reducing the level of resource consumption and reducing the negative externalities. This is essentially a question of efficiency, increases in efficiency ticks both of these boxes, but only efficiency in a holistic sense of how well the whole system works, not simply the efficiency of some subsystem. Overall efficiency means you can do more with less and it also means that you produce less waste and negative externalities.\n\n\u201cThe trends in resources imply that to maintain stable future economies and natural life support systems, resource productivity increases would need to be greater than the rate of economic growth for the world as a whole.\u201d \u2013 UNEP\n\nMacro\u00a0Efficiency\n\nWe can think about sustainable development then as a function of efficiency, if we develop an economic system at a low level of efficiency then it will be unsustainable, consuming more and producing more negative externalities \u2013 for example we might think of the many coal power plants that have fueled China\u2019s economic development which have now led to high levels of air pollution and CO2 emissions. Improving the overall efficiency of natural resource utilization is called decoupling, decoupling the amount of energy and materials used to produce some unit of economic development, decoupling means you can grow the economy while producing less waste and using less resources. We get environmental degradation and an unsustainable dynamic when we develop the economy rapidly while it remains inefficient and coupled to resource demand.\n\nMost people choose the course of least resistance trying to achieve the best outcome with the minimal investment of time, energy and other factors that they value. They choose a course that \u201cfits in\u201d with their environment, that represents the best course given the constraints. But this often represents the least efficient overall solution with the greatest overall negative externalities \u2013 China\u2019s coal power plants again being a good illustration of this \u2013 which we then try and constrain. If we want to change some unsustainable course of action, there are really just two basic approaches, you can try and control the activity by constraining its behaviour to some desired subset of activity, or you can create a better solution that makes the existing detrimental solution look irrelevant, create a better overall solution that is also an easier option than the existing one.\nWe have already tried, for a long time, the first option of constraint, this is largely what the environmental movement has done, tried to prevent people from doing things through conservation, but conservationism seems to have had limited success. Developing a truly sustainable economy won\u2019t come from conservation, constraints and top-down management. It will actually mean creating the future instead of trying to control the past. This means creating a better model that makes the existing solution irrelevant. Building economic and business models that offer both viable and sustainable solutions, making the course of least resistance the course that is also most efficient and sustainable, no small ask.\n\n\u201cThe environmental movement has presented a very negative vision of what we need to do it\u2019s always the things that we have to stop doing, but I think the other side of the coin is that we can really improve the quality of life if we do things differently\u201d \u2013 Dr. Robert Costanza\n\n\nAchieving economic development while reducing environmental impact may be called decoupling, the decoupling of resource demand and externalities from economic development, which is essentially about efficiency, doing more with less. The OECD may be credited with being the first international organization to have adopted the concept of resource decoupling, treating it as one of their main objectives. Decoupling can either reduce the use of resources absolutely as an economy grows or only relatively. With relative decoupling, the rate of increase in resource use is lower than the growth rate of the economy. With absolute decoupling, in contrast, resource use declines, irrespective of the growth rate of the economy. Absolute reductions in resource use are rare; they can occur only when the growth rate of resource productivity exceeds the growth rate of the economy.\n\nWe have already seen much relative decoupling within post-industrial economies through efficiency gains in areas such as housing and transportation, for example, lighter cars mean they consume less energy resulting in decoupling. But achieving the kind of major leap in absolute decoupling that would be required to meet the demands of the environmental crisis, this we are far from achieving. Achieving true decoupling will mean more than efficiency gains within narrow specific subdomains, it will require macro level integration and synergies across the whole economy in order to achieve the kind of coordination that would deliver radical jumps in overall efficiency. Macro level integration could achieve decoupling and the kind of dematerialization required for sustainable development in a world of 9 billion plus people.\n\n\u201cThere is growing evidence that decoupling will be one of the next big opportunities for innovation, wise use of resources, and thus for continued economic development. Policymakers along with corporate leaders with vision and an understanding of political realities can take significant steps to benefit from future resource trends and decoupling opportunities\u201d \u2013 UNEP\n\nSystems Solutions\n\nAchieving this quantum leap through macro-level economic integration and synergies really require a different approach to our existing industrial solutions that have become largely compartmentalized on the macro level. It means looking outside the box of the different domains, developing networks and platforms that cut across those domains, enable transparency, cross-domain collaboration and synergistic solutions to emerge.\n\nWhereas we traditionally try to achieve efficiency by focusing on some specific technology or domain optimizing it in isolation; making more efficient lightbulbs, cars or houses. But the real overall efficiency gains today are not so much in these individual components as in enabling synergies between different systems. In the 20th Century we achieved ever greater efficiency gains through centralization and specialization, but today we have to a large extent reached peak productivity gains from this process. Today with information technology\u2019s capacity to interconnect components parts, the gains in efficiency and productivity are more in networking different technologies and solutions into service systems that create synergies between the different elements, thus doing more with less.\u00a0The next generation circular service business model is all about connections and synergies. Instead of selling \u201cthings\u201d it is about selling solutions that network many different products to enable synergies between them, doing more with less, resulting in dematerialization. So here are our three key ideas for enabling... (truncated)",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9358234406,
        "format_confidence":0.8342096806
    },
    {
        "url":"http:\/\/www.theguardian.com\/science\/2009\/apr\/29\/jack-good-codebreaker-obituary\/print",
        "text":"Jack Good\n\nBletchley codebreaker, he worked closely with Alan Turing\n\nIrving John \"Jack\" Good, who has died aged 92, was a statistician and mathematical genius who, having shown his talent in childhood, made crucial contributions to the successful assault on German codes and ciphers at Bletchley Park during the second world war. Two decades later the director Stanley Kubrick called on him while making 2001: A Space Odyssey (1968).\n\nOn 27 May 1941, fresh from gaining his doctorate at Cambridge, Good walked into Hut Eight, scene of Bletchley Park's attack on German naval ciphers, for his first shift. This was the day that the Royal Navy caught, and destroyed, the battleship Bismarck after it had sunk HMS Hood, the British fleet flagship. Bletchley's contribution had been tangential but important: the discovery by wireless-traffic analysis that the German flagship was bound for Brest in France rather than Wilhelmshaven, from which she had set out, when signals to her started coming from the French port instead of the German one.\n\nBut Hut Eight had not been able to decipher in real time the 22 messages sent to the Bismarck because the Kriegsmarine was better at protecting its wireless traffic than the German army or the Luftwaffe, whose ciphers had been well penetrated the previous year. Naval signals were taking three to seven days to decipher, which usually made them operationally useless for the British. Yet this was about to change.\n\nIn his book Enigma: the Battle for the Code, Hugh Sebag-Montefiore describes how Good annoyed Alan Turing, the great mathematician and guiding intelligence of the Bletchley operation, by taking a nap on the floor of Hut Eight during his first night shift. Turing refused to speak to him afterwards - until the new boy used his statistical expertise to demonstrate how an essential trial-and-error method of attacking Enigma traffic could be accelerated .\n\nThe two men were thus reconciled. On another night shift, Good made a discovery missed by the old hands at Hut Eight. This helped them to work out which pairs of dummy letters the German encoders were adding to the twice enciphered, three-letter group at the start of each signal, telling the recipient how to set his machine to decipher it (for the British this became the achilles heel of the system). Good worked out that the \"padding\" was not random but came from a table, just as the setting itself did.\n\nSome sensitive or important Enigma messages were enciphered twice, once in a special variation cipher and again in the normal cipher. Clearly a man who needed his sleep, Good dreamed one night that the process had been reversed: normal cipher first, special cipher second. When he woke up he tried his theory on an unbroken message - and promptly broke it. He also worked closely with Turing and others on the pioneering Colossus computers used to tackle other German ciphers. By now he was principal statistician.\n\nGood was born Isidore Jacob Gudak to Polish-Jewish parents in London. His father was a watchmaker. He was educated at the Haberdashers' Aske's boys' school then in Hampstead, north London, where he effortlessly outpaced the mathematics teaching curriculum.\n\nIn 1938 he graduated with first-class honours in mathematics from Jesus College, Cambridge and stayed on to work for his PhD. While still at Cambridge, in 1941, he was approached by Bletchley recruiters. These included Hugh Alexander, twice British national chess champion, with whom he was to work closely, Good had won the 1939 Cambridgeshire chess championship. He reported for work within days. His service with Turing lasted nearly two years until he transferred to a team led by Max Newman, working on Colossus.\n\nIn 1947 Newman invited Good to join him and Turing at Manchester University. There for three years he lectured in mathematics and researched computers - including the Manchester Mark 1. Then, in 1948, he was recruited by the Government Communications Headquarters (GCHQ), the successor to Bletchley Park, where he stayed until 1959. This did not prevent him from taking up a brief associate professorship at Princeton University and a short consultancy with IBM.\n\nFrom 1959 until he moved to the US in 1967 he held various government-funded posts and a senior research fellowship at Trinity College, Oxford. He was made a doctor of science at Cambridge in 1963 and at Oxford in 1964. Three years later he was appointed professor of statistics at Virginia Polytechnic Institute and State University.\n\nAs the author of such treatises as Speculations Concerning the First Ultraintelligent Machine and Logic of Man and Machine (both 1965), Good must have seemed the obvious man for Kubrick to consult when making 2001; one of the main characters in the film is the super-computer HAL 9000, which shows intelligence and emotions but goes rogue. Good's published work ran to more than three million words.\n\nSlender and sporting a bushy moustache, Good was not without humour. He published one paper under the names IJ Good and K Caj Doog, his own nickname spelt backwards. In one paper in 1988 he solemnly reviewed other writings on the subject, mainly his own, on the grounds that: \"I have read them all carefully.\" In Virginia, where car owners can invent their own numberplates, he chose 007 IJG in a coy reference to his wartime intelligence role.\n\n\u2022 Irving John \"Jack\" Good, mathematician, born 9 December 1916; died 5 April 2009\n\nToday's best video\n\nToday in pictures",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9783951044,
        "format_confidence":0.9524183273
    },
    {
        "url":"http:\/\/www.ocsef.org\/news\/item\/228-jan-richard-cannon-ocsef",
        "text":"\n\nJan and Richard Cannon 1964\n\n\nWhen Jan Burnett first signed up for the 1964 Orange County Science and Engineering Fair (OCSEF), she had no idea that she would meet her future husband there.\u00a0\n\n\nBecause their last names were close together alphabetically, Jan Burnett\u2019s and Richard Cannon\u2019s projects were right next to each other at the state competition. The two spent the day touring the Fair, watching various science films and getting to know each other.\n\n\n\u201cHe was a surfer and quite different from the rest of my friends in terms of interests and activities, which intrigued me,\u201d Jan Cannon said. \u201cWe started dating and had a lot of fun that summer, going to the beach, dancing and exploring Orange County. We also talked; we talked about everything.\u201d\n\n\nJan Cannon\u2019s lifelong interest in science began with a chemistry set and microscope in elementary school, and was encouraged by her parents, her fifth and sixth grade science teacher and the Space Race of the 1960s.\u00a0This interest led to an eventual career in medical technology and hematology. After certification, Jan Cannon worked as a hematology specialist, educator and lecturer at the University of California, Davis until her retirement from teaching in 2009.\n\n\n\u201cI loved all of this work, but best of all was finding laboratory clues leading to diagnosis and treatment of a patient\u2019s disease,\u201d Jan Cannon said. \u201cIt was very rewarding to provide the information needed to diagnose anemia, leukemia or parasitic infections, to name a few.\u201d\n\n\nJan Burnett and Richard Cannon married in the Clark County Courthouse in Las Vegas, Nev., on June 25, 1965, 13 months after they had met and four months after Richard Cannon enlisted in the United States Air Force. The couple lived in Texas and Florida for two years, and then in Taiwan for two more years.\u00a0While in Taiwan, Jan Cannon taught conversational English to locals. Students included college graduates preparing for their Test of English as a Foreign Language exam to obtain further education in the U.S., members of the local Procter and Gamble factory\u2019s executive board, as well as a police chief.\u00a0\n\n\n\u201cLiving in Taiwan immersed us in a totally different culture and permanently changed my worldview,\u201d Jan Cannon said. \u201cWe had an opportunity to learn, appreciate and respect cultural differences.\u201d\n\n\nAfter service in the Air Force, Richard Cannon taught middle school science before accepting a job at a commercial water treatment company. His scientific background and success in sales led him to start Cannon Water Technology, Inc. in Sacramento in the mid-\u201980s. The Cannons are both still working at their family business but plan to ease into retirement over the next few years.\n\n\n\u201cI feel that science fairs such as the OCSEF act as incubators for creative students who will become the technology and science leaders of the future,\u201d Richard Cannon said. \u201cThough my business is not an extension of my science project on thermal regulation of reptiles, the skills I learned creating my project helped me greatly later in life.\u201d \u00a0\n\n\nThe annual OCSEF serves to encourage students like Jan and Richard Cannon to participate in all fields of science, technology, engineering and mathematics.\u00a0\n\n\n\u201cRealizing that a science fair is judged largely based on evidence is a powerful way to prepare students to make better decisions in all areas of their lives, even if they do not become scientists,\u201d OCSEF director Mark Hobbs said. \u201cWatching the students present [their projects] is definitely the best part of the Fair. It renews my faith in the next generation and the future.\u201d\n\n\nParticipation in the OCSEF has grown steadily over the last few years and sees almost 600 project submissions annually.\n\n\n\u201cThere are many wonderful careers for people with strong aptitudes in science; find out what you love to do,\u201d Jan Cannon said. \u201cHowever, while careers are important, remember to have a balanced life that includes loving, laughing and sharing with others. \u00a0You will have a long life and time for many opportunities and adventures, and maybe even detours. Enjoy them all!\u201d",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.5434958935,
        "format_confidence":0.9459701777
    },
    {
        "url":"http:\/\/www.geolsoc.org.uk\/About\/History\/Obituaries-2001-onwards\/Obituaries-2013\/John-Barry-Dawson-1932-2013",
        "text":"Product has been added to the basket\n\nJohn Barry Dawson 1932-2013\n\ndawsonExpert on kimberlites and their xenoliths, carbonatites and rift magmatism who improved understanding of mantle melting\n\nIt is with a mixture of sadness at his passing and joy at his memory that we pay tribute to an outstanding geoscientist and great man, Barry Dawson.\n\nBarry was an outstanding igneous geologist whose world-class research on kimberlites and their xenoliths, carbonatites and rift-related magmatism significantly improved our understanding of the mantle and its melting. Moreover, his collection of xenoliths and East African Rift volcanics will remain an outstanding resource for decades to come. He was the \u2018Indiana Jones\u2019 of igneous petrology \u2013 returning from remote regions with exceptional geological specimens, and many an amazing tale to recount.\n\nBarry began his studies at Leeds University in 1953, graduating with First Class Honours in 1957 and subsequently a PhD on the kimberlites of Basutoland (Lesotho). He later gained international recognition in kimberlite research for his discovery of diamond in garnet lherzolite, his documentation of the MARID suite of mantle xenoliths, and his studies of mantle metasomatism. Barry joined the Tanganyika Geological Survey and was despatched to examine the 1960 eruption of Ol Doinyo Lengai. He found that many of the fresh lava flows were solidified from molten sodium carbonate, and so resolved the controversy over the origin of carbonatites in the most dramatic way possible - by discovering them erupted from a volcano.\n\nHe went on to determine the physical and chemical properties of natrocarbonatite lavas, re-visiting Oldoinyo Lengai in 1988 to witness this extraordinary volcano in eruption. On leaving Tanganyika in 1962, Barry took up a Postdoctoral Fellowship in Dalhousie University, Nova Scotia. He was appointed to a lectureship at the University of St Andrews in 1964, and promoted to Professor in 1975. In 1978 he became the Sorby Professor of Geology in the University of Sheffield, moving to Edinburgh in 1989 as Professor of Geology until his retirement in 1997. He did not \u2018retire\u2019, but became a very active Emeritus Professor - his latest paper being published in January 2013.\n\nDespite his many years in, and love of, Scotland, Barry remained a proud Yorkshireman. He was excellent company and a great raconteur, always ready with a tale to tell. He was exceptionally generous with his time, wisdom and advice, both to colleagues and postgraduates. He was greatly appreciated for this \u2013 in Edinburgh the postgraduates attending our petrology seminar spontaneously raised glasses of fine malt to toast his memory.\n\nBarry lives on through his scientific legacy. He published numerous papers, a seminal textbook, Kimberlites and their Xenoliths, and collaborated widely. He gained many awards, including election to the Royal Society of Edinburgh in 1972, the Norman L Bowen Award of the American Geophysical Union in 1987, election to the Fellowship of the German Academy of Sciences in 1994, the Clough Medal of the Edinburgh Geological Society in 1999, and the Mineralogical Society\u2019s Collins Medal in 2012.\n\nWe will all miss Barry, but he hasn\u2019t gone completely. Like the Cheshire Cat in Alice's Adventures in Wonderland, he has faded but his grin will remain with us for a long time to come.\n\nSimon L Harley & J Godfrey Fitton",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9118177295,
        "format_confidence":0.9804747701
    },
    {
        "url":"https:\/\/blog.chron.com\/climateabyss\/2011\/08\/texas-drought-a-fingerprint\/",
        "text":"Texas Drought: A Fingerprint\n\nDrought has a variety of impacts.\u00a0 Some droughts can hit agriculture hard.\u00a0 Others affect water supplies.\u00a0 Others affect fire danger.\u00a0 Most affect all three, to varying extents.\u00a0 The length and timing of the drought relative to such things as the growing season determines the impact profile.\n\nI like to compare drought intensities through a type of diagram I created.\u00a0 (Maybe someone else created it before me, but at least I created it independently.)\u00a0 I call it the Drought Fingerprint Diagram.\u00a0 It\u2019s drawn relative to a particular month of the year.\u00a0 Here, we\u2019ll talk about the July diagram.\n\nThe x-axis is the number of months of accumulated precipitation.\u00a0 Suppose the precipitation in July 1993 at a particular location was 2.00 inches.\u00a0 Then the one-month data point for 1993 would be at 2.00\u2033.\u00a0 If June 1993 brought 1.50\u2033 of precipitation, the two-month accumulation would be a total of 3.50\u2033, so that\u2019s the value plotted at two months.\u00a0 Another 3.00\u2033 of rain back in May means that the three-month total is 6.50\u2033, and that\u2019s what\u2019s plotted at three months.\u00a0 And so on, as far back as you\u2019d like to go.\n\nAll the lines slope upward to the right, because each point adds more precipitation from an older month to the current total.\n\nHere\u2019s such a diagram for Texas for the period 1898-2010:\n\nTexas Drought Fingerprints, 1898-2010\n\nThere are 114 lines, one for each July in the period.\u00a0 Some of the more extreme lines are labeled.\u00a0 For example, the driest 4-month period ending in July took place in 1998.\u00a0 Other prominent drought years are 1917, 1956, 1925, and 1918.\u00a0 Conversely, it was very wet leading up to and including July 2007, 1941, and 1992.\n\nOkay, it\u2019s time to play a game we like to call \u201cpredict the likelihood of an extreme event\u201d.\u00a0 Based on historical data such as this, civil engineers all the time have to come up with the probability of an extremely rare event occurring.\n\nIn practice, they do this by fitting a probability distribution to the data, meaning they figure out which bell curve (for example) best fits the distribution of the data.\u00a0 With the curve in hand, they can directly calculate the probability of any event occurring.\u00a0 In principle, they can do this even for events that lie outside the envelope of past events, though the farther you get from the envelope the less accurately you can estimate the probability.\n\nSo we\u2019ll do it the simple way: by eye.\u00a0 Ready?\n\nOkay, look at the graph and estimate for yourself the accumulation over 7 months that would correspond to a 1 in 100 dry event, that is, an event with a probability of 1%.\n\nSince we\u2019ve got about a hundred lines plotted, the simplest approach would be to take the lowest value among the data already plotted.\u00a0 Since 113 out of 114 events were wetter than that in the past, it\u2019s reasonable to guess that about 99 out of 100 future events will also be wetter.\n\nMaybe you\u2019re already beyond that point.\u00a0 Maybe you\u2019re looking at the graph and seeing that the number of dry outliers (graphs that lie well below the general cluster) is quite small, especially for the period 5-10 months.\u00a0 Meanwhile, at the high precipitation end, the spacing between the lines tends to spread out more gradually.\u00a0 Maybe you\u2019re thinking that we\u2019re overdue for a dry outlier.\n\nMaybe you\u2019d like to take climate change into account.\u00a0 Precipitation in Texas has been increasing over the long-term, and you can see that the highest graphs tend to be more recent than the lowest graphs.\u00a0 That would make a dry event less likely.\u00a0 Conversely, climate models project a slow decrease in precipitation: is a dry event more likely?\n\nOkay, that\u2019s fine for a 1 in 100 event.\u00a0 What about a 1 in 200 year event?\u00a0 1 in 500?\n\nHere\u2019s the same graph again, except I\u2019ve added in the 2011 data.\n\nDrought Fingerprints, 1898-2011\n\n\nThe year-to-date precipitation (7-month accumulation period) for 2011 is about 6 inches.\u00a0 The next lowest value is about 9 inches, and most curves seem to be concentrated around the 15-20 inch mark.\n\n2011 is not the low mark just at 7 months.\u00a0 It also takes the record for the following durations ending in July: 2 months, 3 months, 5 months, 6 months, 8 months, 9 months, 10 months, 11 months, and 12 months. Everything from 5 to 10 months breaks the record by a large margin.\u00a0 In fact, everything from 8 to 10 months breaks the record for consecutive months, no matter the ending month.\n\nSo we now have a dry outlier that\u2019s even more an outlier than the wet outlier of 2007.\u00a0 What are the odds of such an event occurring?\u00a0 I had them at about 1 in 250.\u00a0 What about you?\n\nWhatever the exact value, it\u2019s obvious that Texas is living through a very unusual weather event.\u00a0 I don\u2019t consider it to be the worst drought on record, because the 1950s drought lasted for seven years, and 1956 alone gives 2011 a run for its money.\u00a0 But, combine it with July being the warmest month on record for Texas, and it probably becomes the most unbearable.\u00a0 It may well be the worst drought on record for agriculture.\n\nJohn Nielsen-Gammon",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9935349226,
        "format_confidence":0.7321055532
    },
    {
        "url":"https:\/\/yourstory.com\/2017\/12\/2-lakh-trees-ngo-regenerating-forest-tamil-nadu\/amp",
        "text":"With over 2 lakh trees, this NGO is regenerating a forest in Tamil Nadu\n\nThe Forest Way, a non-profit dedicated to restoring nature, has been generating employment and recreation for indigenous communities while protecting forests for nearly a decade.\n\nThe indispensable importance of forests is certainly not a subject that most people are unaware of. From a home to flora and fauna to being an important factor that helps mitigate climate change, our dependence on forests begin right from the air we breathe to the wood we use.\n\nActive learning at the Marudam Farm School.\n\nThis once abundant abode of resources however, is slowly turning extinct in our country due to increased land use, overgrazing and indiscriminate felling of trees. India is losing 1.5 million hectares of forest cover every year and at this rate it won\u2019t be long before our forests are depleted entirely.\n\nIn light of all that has been happening, working endlessly to do their bit towards protecting forests is The Forest Way (TFW). An organisation based in the town of Thiruvannamalai, Tamil Nadu, TWF has been regenerating a forest on the sacred Arunachala hill and also supporting families from the villages around the hill.\n\nFor the cause of ecological restoration\n\nThe Forest Way was founded back in 2003 when a team of seven joined forces to heal the damaged environment. Fifty-year-old V. Arun, a qualified engineer, quit a mainstream job to take up conservation and education. He worked in the Krishnamurti foundation school in Chennai for 12 years before moving to Thiruvannamalai to start the trust. He says, \u201cWe came together, not trying to solve a problem but just to do what we can, as conscious individuals. We are deep into the sixth extinction and we can only postpone the inevitable. Socially speaking we can try and live by what we think is right and this is what we as a trust want to do.\u201d\n\nThe team with friends.\n\nGovinda, another primary member of the team, is of British origin, he shares, \u201cI have lived in India for nearly 20 years and came here on a spiritual search but later was drawn in to ecological restoration. My wife and I have ever since been an integral part this project.\u201d\n\nRaising saplings in the nursery.\n\nSince the Arunachala hill is sacred and famous worldwide, Govinda was immediately drawn to it when he first moved to Thiruvannamalai. \u201cThe hill was the nearest largest green region and could serve as an example to what we had set out to achieve. Also, Arun\u2019s great grandfather lived with Ramana Maharshi, a famous saint from here. So, this was his first choice too.\u201d\n\nTFW was officially registered in 2008, with a core team of members from different walks of life, a violinist, teachers, entrepreneurs and a full time conservationist among others, who have been living together with the indigenous community in thatch houses powered by solar energy, also growing their own food in attempt to live sustainably.\n\nRejuvenation in full swing\n\nThe team at TFW started its projects with fervour and have been faithfully working towards turning the Arunachala hill into a region thriving with biodiversity. Its main work is centred around raising a nursery of 25,000 to 30,000 indigenous saplings a year, out of which on an average 15,000 saplings are planted on the hill every year.\n\nFire prevention awareness.\n\nTo protect these growing saplings and already existing trees the team creates and maintain fire lines crisscrossing the hill for about 20 kilometres, to prevent fires from spreading all over. With an experienced fire-fighting team in place, TFW also manages to actively fight unexpected fires at any given time, shares Arun.\n\nThe team also supports 60 families through the year. During the afforestation and fire line creating process they employ more than a 100 people. Alongside providing employment for adults, TFW also runs an alternative school called, Marudam Farm School for children between the ages of 4-10. As the name suggests, the school is located on an eight-acre organic farm with native crops and vegetables. The food grown on the farm is used to feed the 70 children in school.\n\nFire fighting.\n\n\u201cOur hope is that an education at Marudam Farm School will help to bring about sensitive and intelligent human beings. Children will discover not only their interests and passions, but also nurture skills in both academic and non-academic areas that will help them meet any life challenges. We care for the land and use it as a rich educational resource, integral to the learning process,\u201d explains Arun.\n\nTheir contributions do not end here, TWF also runs a children's park at the base of the hill for recreational purposes, free for the public of the town to use and a forest park with indigenous trees for educational purposes.\n\nChildren's park\n\nFighting through hindrances\n\nThe team is grateful that since they began operating, it has had a beautiful run with lots of success and very little negatives.Their biggest speed bump was when Thiruvannamalai suffered the worst drought it has seen in 140 years, this year. \u201cThe drought was severe across the country. Farming had completely ground to a halt for a year. Many plants and wild animals died, especially spotted deer. But things turned around for the better in August when we received 50cm of rainfall which filled up the water bodies.\u201d\n\nThe team has doubled its efforts to undo the damage and have begun work by planting 10,000 saplings.. \u201cThis year we are also planting close to the peak of the hill, which involves a trek of over two hours. We have now also taken up the process of restoring a lake, Thamarai Kolam which is home to many species of water birds,\u201d says Arun.\n\nTree planting by school kids.\n\nThe lake restoration project seeks to generate employment to sustain around 50 families and create a new park around the bund of the lake. \u201cWe wish to reclaim this lake for the community and are planning to take this up in stages and are in dire need of funds.\u201d To meet expenses, TFW has launched #RestoreThiruvannamalai campaign and are also looking for offline donations. \u201cSo far we have raised funds from the interested public only. Through this campaign we want to reach out to everyone.\u201d\n\nNo longer barren land\n\nPlanting saplings on the hilltop every year.\n\nThe sweat and toil the team has put into the greening of the hill has had a magical effect on the local fauna. With the green cover on the hill returning the number of the fauna has risen exponentially. \u201cThe current count of bird species is 202. The other animals to have returned are spotted deer, porcupines, jungle cat, civet cat and pangolin. This hill that was barren for nearly a century, today is covered with a thick green cover and is fast emerging as a successful replicable model.\u201d\n\nTFW has planted over two lakh trees, helped prevent fires and foster a sustainable community that actively participates with the team in a decade of their existence. Not looking to slow down anytime in the future, the nearly 80-member team is looking to adopt two more water bodies, publish a book on Thiruvannamalai birds and are on the verge of leasing a 3 acre land to start a weaving unit and cotton growing project.\n\nIts goal here on is to raise employment for the local population and grow organically. If anything, this not-for-profit inspires us to learn from indigenous communities and look to learn from nature\u2019s ways, suggesting that a little positive action can have an even bigger impact in the long haul.\n\nRead Next",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9698496461,
        "format_confidence":0.8923515677
    },
    {
        "url":"http:\/\/www.airspacemag.com\/space\/explorers-wanted-5315578\/?page=2",
        "text":"Explorers Wanted\n\nHey, kids! The NASA Administrator says you're going to Mars! (Do your homework.)\n\nAir & Space Magazine | Subscribe\n\n(Continued from page 1)\n\nSoon after Opportunity's landing, the rover was busily ratting into rock outcrops, where it found BB-size spheres, formed in the distant past by minerals dissolving out of Martian rock. The scientists nicknamed these \"blueberries.\" An instrument called a M\u00f6ssbauer spectrometer, tuned to discriminate among various kinds of iron, identified a mineral called jarosite\u2014further evidence of water. Yet another spectrometer revealed sulfur-bearing salts that typically form in wet environments. The ripples and layering in the rocks, along with other clues, gave the researchers more confidence in their conclusion that the rocks in Eagle Crater had once been drenched with water.\n\nWeeks later, inside a larger crater called Endurance, Opportunity found additional signs that the planet had once been wet. When it looked as though Spirit would come up empty, in April scientists announced that it, too, had found traces of past water seepage from a crack in a half-buried rock called Mazatzal. Not as dramatic as Opportunity's salty sea, maybe, but evidence just the same.\n\nThe travels of Spirit and Opportunity mark a new age of Mars exploration. Not only are two rovers operating simultaneously on the planet's surface for the first time, but the expedition uses data and radio relays from three more satellites in orbit\u2014Mars Global Surveyor, Mars Odyssey, and Europe's Mars Express. The last arrived in December for its own extended study of the planet, and immediately made the first direct measurement of water in the planet's polar cap. In 2004, Mars was a busy place.\n\nHigh-resolution pictures from the Mars Global Surveyor were key to mapping the rovers' route (see below). Spirit landed not far from Bonneville crater, which project scientists picked as an early destination. When Bonneville proved a disappointment (no rock outcrops), the rover set off on a long journey to the 330-foot-high Columbia Hills, nearly two miles away. The attraction for scientists was that these rocks are higher, and likely to be of a different age, than those near the landing site. Spirit reached the base of the hills in mid-June, and was still exploring them in late summer.\n\nThe Mars rovers were built to last at least 90 Martian days, but project officials always knew this was just \"the warranty period,\" as JPL engineers put it, and that the machines were likely to last longer. By the time the nominal 90-Sol mission was over, the odometer on the golf-cart-size Spirit read 637 meters\u2014about 4\/10 of a mile. By late summer the rover had traveled several times that distance, and NASA had decided to extend the mission\u2014as if shutting down two healthy Mars rovers was even an option.\n\nMeanwhile, engineers back on Earth were preparing more Mars missions, which will be launched in 2005, 2007, and 2009. With about as much land mass on this dry planet as Earth has on its watery surface, Mars still offers plenty of territory to explore.\n\n\u2014The editors\n\n\nComment on this Story\n\ncomments powered by Disqus",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9923341274,
        "format_confidence":0.6109095812
    },
    {
        "url":"https:\/\/afdportland.wordpress.com\/2009\/12\/08\/manufacturing-doubt-and-the-hacked-global-warming-emails-%E2%80%8F\/",
        "text":"Alliance for Democracy\n\nManufacturing Doubt and the Hacked Global Warming\u00a0emails.\u200f\n\nPosted in global warming, lung cancer, manufactured doubt, ozone hole by Alliance for Democracy Portland OR on December 8, 2009\n\nLikely you have heard of the current controversy surrounding leaking documents from the files of global warming scientists in Europe.\u00a0 These documents have poured over by climate change skeptics who suggest that the scientists have been dishonest in their findings.\n\nThe following lengthly article discusses this controversy in the context of other corporate efforts at Manufactured Doubt.\u00a0\n\nDavid e. Delk, Alliance for Democracy \u2013 Portland Chapter 503 232 5495\nThis email will be posted on\u00a0 the Alliance for Democracy blog for your comments at\n\nPublished on Monday, December 7, 2009 by Weather Underground\n\nThe Manufactured Doubt Industry and the Hacked Email Controversy\n\nby Jeff Masters\n\n\u00a0In 1954, the tobacco industry realized it had a serious problem. Thirteen scientific studies had been published over the preceding five years linking smoking to lung cancer. With the public growing increasingly alarmed about the health effects of smoking, the tobacco industry had to move quickly to protect profits and stem the tide of increasingly worrisome scientific news. Big Tobacco turned to one the world\u2019s five largest public relations firms, Hill and Knowlton, [1] to help out. Hill and Knowlton designed a brilliant Public Relations (PR) campaign to convince the public that smoking is not dangerous. They encouraged the tobacco industry to set up their own research organization, the Council for Tobacco Research (CTR), which would produce science favorable to the industry, emphasize doubt in all the science linking smoking to lung cancer, and question all independent research unfavorable to the tobacco industry. The CTR did a masterful job at this for decades, significantly delaying and reducing regulation of tobacco products. George Washington University epidemiologist David Michaels, who is President Obama\u2019s nominee to head the Occupational Health and Safety Administration (OSHA), wrote a meticulously researched 2008 book called, Doubt is Their Product: How Industry\u2019s Assault on Science Threatens Your Health. [2] In the book, he wrote: \u201cthe industry understood that the public is in no position to distinguish good science from bad. Create doubt, uncertainty, and confusion. Throw mud at the anti-smoking research under the assumption that some of it is bound to stick. And buy time, lots of it, in the bargain\u201d. The title of Michaels\u2019 book comes from a 1969 memo from a tobacco company executive: \u201cDoubt is our product since it is the best means of competing with the \u2018body of fact\u2019 that exists in the minds of the general public. It is also the means of establishing a controversy\u201d. Hill and Knowlton, on behalf of the tobacco industry, had founded the \u201cManufactured Doubt\u201d industry.\n\nThe Manufactured Doubt industry grows up\n\nAs the success of Hill and Knowlton\u2019s brilliant Manufactured Doubt campaign became apparent, other industries manufacturing dangerous products hired the firm to design similar PR campaigns. In 1967, Hill and Knowlton helped asbestos industry giant Johns-Manville set up the Asbestos Information Association (AIA). The official-sounding AIA produced \u201csound science\u201d that questioned the link between asbestos and lung diseases (asbestos currently kills 90,000 people per year, according to the World Health Organization [3]). Manufacturers of lead, vinyl chloride, beryllium, and dioxin products also hired Hill and Knowlton to devise product defense strategies to combat the numerous scientific studies showing that their products were harmful to human health.\n\nBy the 1980s, the Manufactured Doubt industry gradually began to be dominated by more specialized \u201cproduct defense\u201d firms and free enterprise \u201cthink tanks\u201d. Michaels wrote in Doubt is Their Product about the specialized \u201cproduct defense\u201d firms: \u201cHaving cut their teeth manufacturing uncertainty for Big Tobacco, scientists at ChemRisk, the Weinberg Group, Exponent, Inc., and other consulting firms now battle the regulatory agencies on behalf of the manufacturers of benzene, beryllium, chromium, MTBE, perchlorates, phthalates, and virtually every other toxic chemical in the news today\u2026.Public health interests are beside the point. This is science for hire, period, and it is extremely lucrative\u201d.\n\n\u00a0Joining the specialized \u201cproduct defense\u201d firms were the so-called \u201cthink tanks\u201d. These front groups received funding from manufacturers of dangerous products and produced \u201csound science\u201d in support of their funders\u2019 products, in the name of free enterprise and free markets. Think tanks such as the George C. Marshall Institute, Competitive Enterprise Institute, Heartland Institute, and Dr. Fred Singer\u2019s SEPP (Science and Environmental Policy Project) have all been active for decades in the Manufactured Doubt business, generating misleading science and false controversy to protect the profits of their clients who manufacture dangerous products.\n\n\u00a0The ozone hole battle\n\nIn 1975, the chlorofluorocarbon (CFC) industry realized it had a serious problem. The previous year, Sherry Rowland and Mario Molina, chemists at the University of California, Irvine, had published a scientific paper warning that human-generated CFCs could cause serious harm to Earth\u2019s protective ozone layer. They warned that the loss of ozone would significantly increase the amount of skin-damaging ultraviolet UV-B light reaching the surface, greatly increasing skin cancer and cataracts. The loss of stratospheric ozone could also significantly cool the stratosphere, potentially causing destructive climate change. Although no stratospheric ozone loss had been observed yet, CFCs should be banned, they said. The CFC industry hired Hill and Knowlton to fight back. As is essential in any Manufactured Doubt campaign, Hill and Knowlton found a respected scientist to lead the effort\u2013noted British scientist Richard Scorer, a former editor of the International Journal of Air Pollution and author of several books on pollution. In 1975, Scorer went on a month-long PR tour, blasting Molina and Rowland, calling them \u201cdoomsayers\u201d, and remarking, \u201cThe only thing that has been accumulated so far is a number of theories.\u201d To complement Scorer\u2019s efforts, Hill and Knowlton unleashed their standard package of tricks [4] learned from decades of serving the tobacco industry:\n\n  \u2022 Launch a public relations campaign disputing the evidence.\n  \u2022 Predict dire economic consequences, and ignore the cost benefits.\n  \u2022 Use non-peer reviewed scientific publications or industry-funded scientists who don\u2019t publish original peer-reviewed scientific work to support your point of view.\n  \u2022 Trumpet discredited scientific studies and myths supporting your point of view as scientific fact.\n  \u2022 Point to the substantial scientific uncertainty, and the certainty of economic loss if immediate action is taken.\n  \u2022 Use data from a local area to support your views, and ignore the global evidence.\n  \u2022 Disparage scientists, saying they are playing up uncertain predictions of doom in order to get research funding.\n  \u2022 Disparage environmentalists, claiming they are hyping environmental problems in order to further their ideological goals.\n  \u2022 Complain that it is unfair to require regulatory action in the U.S., as it would put the nation at an economic disadvantage compared to the rest of the world.\n  \u2022 Claim that more research is needed before action should be taken.\n  \u2022 Argue that it is less expensive to live with the effects.\n\n\nThe campaign worked, and CFC regulations were delayed many years, as Hill and Knowlton boasted [5] in internal documents. The PR firm also took credit for keeping public opinion against buying CFC aerosols to a minimum, and helping change the editorial positions of many newspapers.\n\nIn the end, Hill and Knowlton\u2019s PR campaign casting doubt on the science of ozone depletion by CFCs turned out to have no merit. Molina and Rowland were awarded the Nobel Prize in 1995. The citation from the Nobel committee credited them with helping to deliver the Earth from a potential environmental disaster.\n\nThe battle over global warming\n\n\u00a0In 1988, the fossil fuel industry realized it had a serious problem. The summer of 1988 had shattered century-old records for heat and drought in the U.S., and NASA\u2019s Dr. James Hansen, one of the foremost climate scientists in the world, testified before Congress that human-caused global warming was partially to blame. A swelling number of scientific studies were warning of the threat posed by human-cause climate change, and that consumption of fossil fuels needed to slow down. Naturally, the fossil fuel industry fought back. They launched a massive PR campaign that continues to this day, led by the same think tanks that worked to discredit the ozone depletion theory. The George C. Marshall Institute, [6] the Competitive Enterprise Institute, [7] Heartland Institute, [8] and Dr. Fred Singer\u2019s [9] SEPP (Science and Environmental Policy Project) have all been key players in both fights, and there are numerous other think tanks involved. Many of the same experts who had worked hard to discredit the science of the well-established link between cigarette smoke and cancer, the danger the CFCs posed to the ozone layer, and the dangers to health posed by a whole host of toxic chemicals, were now hard at work to discredit the peer-reviewed science supporting human-caused climate change.\n\n\u00a0As is the case with any Manufactured Doubt campaign, a respected scientist was needed to lead the battle. One such scientist was Dr. Frederick Seitz [10], a physicist who in the 1960s chaired the organization many feel to be the most prestigious science organization in the world\u2013the National Academy of Sciences. Seitz took a position as a paid consultant for R.J. Reynolds tobacco company beginning in 1978, so was well-versed in the art ... (truncated)",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.6709406376,
        "format_confidence":0.5582387447
    },
    {
        "url":"http:\/\/blogs.scientificamerican.com\/observations\/asteroid-hunter-gives-an-update-on-the-threat-of-near-earth-objects\/",
        "text":"Opinion, arguments & analyses from the editors of Scientific American\n\nAsteroid Hunter Gives an Update on the Threat of Near-Earth Objects\n\n\nTwo very different asteroids. Photo courtesy of NASA\n\nAn Earth impact by a large comet or asteroid could knock out human civilization with a single blow, as most people are now aware thanks to recent Hollywood movies and public outreach by planetary scientists. Since 1998, when NASA initiated its Spaceguard program to find comets and asteroids 1 km in diameter and larger, researchers have made some crucial inventories of the risky space rocks with orbits that come into close proximity of Earth. For instance, there are almost 1,000 of these so-called near-Earth objects with diameters of 1-kilometer or more.\n\nHowever disconcerting this might seem, we can rest assured that none will make it here in our lifetimes. \u201cWe can say with a very good deal of certainty that no asteroid or comet large enough to threaten life as we know it will hit Earth in the next 100 years,\u201d says Donald Yeomans. At NASA\u2019s Jet Propulsion Laboratory, Yeomans is a senior research scientist and manager of the Near-Earth Object Program Office. He has spent his career studying the physical and dynamical modeling of near-Earth objects, as well as tracking them down.\n\nYeomans works with an international network of professional and amateur astronomers who find and monitor asteroids and comets with orbits that come within approximately 0.33 AU, which is equivalent to 150 million kilometers. The team has identified 8,800 near-Earth objects as of early 2012, he noted during a talk at the American Museum of Natural History in New York on January 14 on his new book Near-Earth Objects, Finding Them Before They Find Us. The book gives readers an inside account of the latest efforts to find, track and study life-threatening asteroids and comets.\n\nThere are literally millions of asteroids and comets in the solar system, ranging in size from the microscopic to hundreds of kilometers in diameter. Both are made of rocky, metallic materials that failed to aggregate into planets during the early days of the solar system. Yeomans says the only real difference between asteroids and comets is that a comet actively loses its dust and ice when near the sun, causing a highly visible tail to form behind it.\n\nScientists have made exponential progress in identifying and tracking near-Earth objects in the past decade. NASA-sponsored near-Earth object surveys have found 90 percent of all asteroids and comets larger than a kilometer in diameter and projected their orbits at least 100 years into the future. Yeomans says the challenge now is finding all asteroids larger than 35 meters across, the size where one would pose a threat to a town or city, rather than all life on Earth.\n\nHistorically, Earth impacts by large asteroids and comets are rare. In addition, there is no clear record of a person being killed by one. Yeomans says that while Earth impacts by large asteroid and meteors are very low probability events, they are of very high consequence.\n\nA prime example is just outside Winslow, Ariz., where a large crater was blasted into the Earth 50,000 years ago by a nearly 30-meter asteroid. Despite its relatively small size, the asteroid generated around 10 megatons of energy upon collision. By comparison, the atomic bomb dropped on Hiroshima during World War II generated around 0.02 megatons.\n\nThe asteroid that killed the dinosaurs 65 million years ago was much larger\u2014a chunk of rock 10 to 15 kilometers across. The crater that formed when it struck near what is now the Yucat\u00e1n Peninsula is 150 kilometers in diameter. The impact caused an immense explosion that deposited a layer of debris 10 meters deep as far as several hundred kilometers away from the impact and rained burning ash down on all corners of the globe. Most animals on the surface of the Earth died, and debris in the upper atmosphere launched the planet into a global winter. Many of the life forms that survived were either in the ocean or underground.\n\nToday, if a survey detected a giant NEO headed for Earth, Yeomans says, humanity would have more than 50 years to prepare for it. He says a spacecraft could theoretically be used to divert such an asteroid off its Earth-colliding trajectory and out into space, and put in his plug for his employer, or at least organizations that support human ingenuity. \u201cWe have conceptual plans on how this could be done,\u201d he says. \u201cThe reason the dinosaurs went extinct is because they didn\u2019t have a space program.\u201d\n\nThe views expressed are those of the author and are not necessarily those of Scientific American.\n\nShare this Article:\n\n\nYou must sign in or register as a member to submit a comment.\n\nThe perfect movie companion to\nJurassic World\n\nAdd promo-code: Jurassic\nto your cart and get this digital issue for just $7.99!\n\nHurry this sale ends soon\u00a0>\n\n\nEmail this Article",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9967381358,
        "format_confidence":0.7940322757
    },
    {
        "url":"https:\/\/thenewtropic.com\/miami-sunset\/",
        "text":"Miami\u2019s sunsets are beautiful, because\u00a0science.\n\nMiami doesn\u2019t have mountains, but man does it have a killer sky. In the past few weeks our sunsets have been out of control, crazy beautiful.\n\nWe asked the National Oceanic and Atmospheric Association (NOAA) what determines whether a sunset is going to be \u201cmeh\u201d or \u201coh my god.\u201d Here\u2019s the \u201cSunsets for dummies\u201d explanation:\n\nClean air is the main ingredient\n\nYou might have heard that pollution is the real cause of our gorgeous sunsets, but if that were true then New York, Los Angeles, London, and Mexico City would probs have the most beautiful skies ever. But they don\u2019t. That\u2019s because when there\u2019s a ton of pollution, it dulls the sky\u2019s colors instead of enhancing them. Myth busted.\n\nThe colors are made by a scattering of light\n\nLight waves (Courtesy of NASA) Here\u2019s how it works. There are a bunch of tiny air molecules in the sky. When the sunlight hits these air molecules, it bounces off of them and scatters. That\u2019s why the sky is blue. Blue light waves are shorter than any other ones so they get hit more by air molecules and scatter more.\n\nImagine a beam of white light being full of all five of these waves. As the sun gets lower, it\u2019s going through more of the atmosphere, so those blue waves that are easy targets for air molecules are getting scattered and re-scattered, and knocked out of the way. That makes the reds, oranges, and yellows easier to get hit and scattered, and easier to see for us.\n\nThose evening thunderstorms are key\n\nThe late afternoon and early evening thunderstorms create nice cloud debris that help scatter the light, creating brilliant varied hues. But it also creates patterns where the sun\u2019s rays are peeking out of the clouds. Clouds can linger anywhere from 15 minutes to hours after the storm, depending on the day and type of storm, so there\u2019s no real way to approximate how soon after a storm a beautiful sunset will follow. But if there are some clouds in the sky, it\u2019ll be a beaut, that\u2019s for sure.\n\nFall and winter are the best times to see them\n\nWalking around Miami in the summer, we know that the air circulation is not happening. That\u2019s why summer sunsets don\u2019t compare to the fall or winter ones. Fall officially started on Sept. 22, but the day just before that, Miami was hit with one of the most beautiful sunsets we\u2019ve seen in awhile. Social media was going nuts over it. Part of that is because the fall brings more air circulation, and more scattering of the light.",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.862845242,
        "format_confidence":0.6581121683
    },
    {
        "url":"http:\/\/edition.cnn.com\/2012\/08\/14\/opinion\/life-oceans-moons-jupiter\/index.html",
        "text":"Aliens in the oceans -- searching for life on the moons of Jupiter\n\nJupiter&#39;s moon Europa has a crust made up of blocks, evidence that Europa may have once had a subsurface ocean.\n\nStory highlights\n\n  \u2022 Moons Europa, Enceladus, and Titan are covered with solid water ice\n  \u2022 Scientist Kevin Peter Hand says there could be vast liquid water oceans underneath the ice\n  \u2022 These oceans could be great homes for alien ecosystems, says Hand\n  \u2022 Exploring Earth's oceans might help us understand fundamental geological and biological cycles\n\nAs the Curiosity rover begins its exciting trek across the surface of Mars and up the dramatic peak of Mt. Sharp it is important to realize that the plans for this great success were incubated and acted upon more than 10 years ago. Exploration like this is not for the faint of heart -- it takes time and persistence.\n\nSo what's next? What is in the funded pipeline now that will be revolutionizing our understanding of life in the solar system 10 or even 20 years from now? The short answer is -- nothing. Curiosity is it. After Curiosity there is, at present, no other mission in production that will explore potentially habitable worlds beyond Earth.\n\nBut where do we want to go? Where do we hope we'll be? Along with continuing our exploration of Mars there are several moons of Jupiter and Saturn that we think might be good places for life.\n\nKevin Peter Hand\n\nThese moons -- worlds with names like Europa, Enceladus, and Titan -- are covered with solid water ice, beneath which we have very good reason to believe that vast liquid water oceans exist.\n\nAnd when I say liquid water I mean good old-fashioned H2O; if you drank this stuff it would probably taste similar to a big gulp of salty ocean water from our ocean here on Earth.\n\nThese are oceans that exist today and have likely been in existence for much of the history of the solar system. Why is this important? Well, if we've learned anything about life on Earth it's that where you find liquid water you generally find life.\n\nThese moons have lots and lots of water and they could be great homes for alien ecosystems (note that when I say \"alien ecosystems\" I'm referring primarily to microbes and simple life forms. As much as I'd love to discover creatures like those seen in the movie The Abyss, I'll be happy just to find a considerable speck of a microbe!)\n\nOne moon in particular -- Jupiter's moon Europa -- may have the perfect combination of liquid water and the chemistry needed for life.\n\nEuropa is about the size of our Moon and beneath its icy shell Europa harbors a global liquid water ocean of roughly 100 km in depth (by comparison, Earth's ocean has an average depth of 4 km and a maximum depth of 11 km). The ocean of Europa contains about 2-3 times the volume of all the liquid water on Earth.\n\nIt's an ocean that's there today and has likely been in existence for much of the 4.6 billion years of our Solar System's history. As such, Europa provides an incredibly compelling place to go to search for a second, independent origin of life and it's a place where we might find lifeforms that are alive now, today.\n\nThis is important for two reasons. First, we need to know if the origin of life is easy or hard. Does life arise wherever the conditions are right or is it a rare occurrence in our Universe? Second, all life on Earth -- from microbes to man -- runs on the same fundamental biochemistry of DNA, RNA, and proteins.\n\nSee also: The search for dark matter\n\nWe want to probe the question of whether or not there exists another way to get the \"business\" of life done. Is there another game in town beyond the biochemistry we see here on Earth? By going to Europa we can address both of these fundamental questions.\n\n360 view of Mars\n360 view of Mars\n\n\n    360 view of Mars\n\n\n360 view of Mars 02:13\nNASA&#39;s &#39;Mohawk Guy&#39; celebrates Curiosity\nNASA's 'Mohawk Guy' celebrates Curiosity\n\n\n    NASA's 'Mohawk Guy' celebrates Curiosity\n\n\nNASA's 'Mohawk Guy' celebrates Curiosity 01:19\n\nMars may have once been habitable but on Mars we are looking for signs of life trapped in the rocks (essentially molecular fossils of microbes).\n\nIn addition, Mars and the Earth are so close that asteroid impacts in the past might have seeded either world with life from the other. Europa is likely too far away for this kind of interplanetary \"seeding.\"\n\nMore: What we've done on Mars, and what's next\n\nWhy do we even think that life could exist on Europa? Here's where the exploration of our own ocean serves as an important guide.\n\nFor much of human history we have focused on discovering new lands and exploring continents. For the most part, we've only skimmed across the top of the ocean. But in the spring of 1977 explorers cruising the dark depths of our ocean discovered that active geological regions on the ocean's floor -- known as hydrothermal vents -- were home to vibrant ecosystems of organisms large and small.\n\nThese are ecosystems that thrive despite the tremendous pressure, and despite the lack of energy directly from the Sun. The base of the foodchain down there is not photosynthesis but rather chemosynthesis, since the microbes are deriving energy from the chemistry of the hydrothermal vents fluid.\n\nThe discovery of ecosystems in the deepest parts of our ocean is continuing to change our understanding of habitable environments here on Earth, and also of potentially habitable environments beyond Earth.\n\nOn Europa we expect that the temperature, pressure, and chemistry of the seafloor might not be that different from our own ocean's seafloor. In the decades to come our pipeline of exploration must include rigorous exploration of our own ocean so as to better understand the fundamental geological and biological cycles here on Earth.\n\nThis research has the added benefit of feeding forward into our efforts to explore potentially habitable oceans in the far reaches of our solar system.\n\nBut some may ask: Why? Why do these things? Granted, this is not going to change the way you make your coffee in the morning. Sure, there are spinoff technologies and many jobs created but that is not at the heart of why we do these things.\n\nThe drumbeat of human civilization is the pursuit of new knowledge. We explore, we discover, and we advance. From fundamental research on cancer to revolutionizing our understanding of the universe, it is not an either\/or: we must do it all.\n\nAnything less is a sign that our priorities as a race have been hijacked by agendas beneath our potential. As has become a refrain in my community, the drumbeat continues and we echo the wise words of Teddy Roosevelt: Dare mighty things.\n\nRead more about space and science on CNN's Light Years blog",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9968337417,
        "format_confidence":0.9406000376
    },
    {
        "url":"https:\/\/www.newscientist.com\/letter\/mg23230961-400-8-evolutionary-forces-may-evolve-too\/",
        "text":"Learn something new every day |\n\nSubscribe and treat yourself to a FREE gift\n\nPublished 19 October 2016\n\nEvolutionary forces may evolve too\n\nFrom Matt Black\n\nThe description of evolution evolving was a much needed summary for many who have long viewed the \u201cselfish gene\u201d theory as too narrow. But a word missing from the article was \u201cfeedback\u201d. The realisation that information flows from organism to environment and the other way, so that each modifies the other, implies a feedback loop.\n\nI am now inspired to look at the work of Stuart Kauffman and others modelling how networks of genes evolve to the \u201cedge of chaos\u201d. The emergence of similar forms by seemingly separate evolutionary pathways may be the result of \u201cstrange attractors\u201d in the evolutionary space.\n\nPerhaps Richard Dawkins's greatest contribution wasn't the popularisation of the \u201cselfish gene\u201d meme, but the concept of the \u201cmeme\u201d itself as a unit of cultural inheritance. Still, the meme has been slippery to define.\n\nBlockley, Gloucestershire, UK",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9954215884,
        "format_confidence":0.5850375295
    },
    {
        "url":"https:\/\/ceramics.org\/ceramic-tech-today\/anything-but-ordinary-latest-glass-innovations-report-strength-surpassing-steel-integrated-but-unobtrusive-displays",
        "text":"Anything but ordinary: Latest glass innovations report strength surpassing steel, integrated but unobtrusive displays | The American Ceramic Society\n\nAnything but ordinary: Latest glass innovations report strength surpassing steel, integrated but unobtrusive displays\n\n1120ctt glasses lo res\n\n[Image above] Innovations with lightguide optics are putting high-tech displays within glass.\u00a0Credit: Juha Sarkkinen; VTT\u00a0\n\nGlass is awesome.\n\nThe material makes so much of modern life possible, yet it\u2019s often barely recognized as such a transformative material.\n\nGlass makes possible the high-tech, yet it also subtly enhances our everyday lives\u2014it makes your morning commute safer, lets more than just light in, keeps seafarers on course,\u00a0enables land speed record attempts, foils the paparazzi\u2014and much, much more.\n\nGlass\u2019s ubiquity but relative obscurity is something that was recently discussed by glass experts at the first workshop of the Functional Glass Manufacturing Innovation Consortium (FGMIC), held a couple of weeks ago in Columbus, Ohio. FGMIC, funded by the NIST Advanced Manufacturing Technology program, is making a roadmap for the functional glass industry, charting some of the biggest challenges and best bets for future research, to help guide the course of a to-be-created consortium.\n\nIn addition to the material\u2019s everyday obscurity, glass often isn\u2019t what people think\u2014it\u2019s not the thick and breakable material that most people conjure up when they hear \u201cglass.\u201d\n\nInstead, glass is smart. It\u2019s high-tech. And it keeps getting stronger and thinner.\n\nFor instance, Japanese researchers recently reported that they have made important\u2014although preliminary\u2014progress on glass that\u2019s almost as strong as steel. The researchers publish in Scientific Reports that they were able to make teeny tiny amounts of glass that contains 50% alumina, giving the material a Young\u2019s modulus to match steel.\n\nWhat\u2019s perhaps even more interesting is that the researchers achieved this feat without a container\u2014they used aerodynamic levitation to float the mixture in air. Containerless fabrication allowed the scientists to bypass problems of\u00a0previous attempts to make alumina-fortified glass, in which the glass\u00a0crystallized\u00a0at points of contact with the container. Plus, containerless fabrication is something of a holy grail when it comes to glass manufacturing.\n\n\u201cWe will establish a way to mass-produce the new material shortly,\u201d study co-author Atsunobu Masuno says in an article about the research in The Asahi Shimbun. \u201cWe are looking to commercialize the technique within five years.\u201d\n\nIn addition to being stronger than ever, glass can do things we never though possible.\n\nRemember this story from a year and a half ago? The one where scientists demonstrated the first example of high-quality photonic waveguides laser-carved into Gorilla Glass?\n\nWhile those scientists were brining the brains to smartphones, researchers from VTT Technical Research Centre of Finland are now using a similar technology of lightguide optics to put the smarts in eyeglasses.\n\nVTT scientists have developed lightguide display technology to integrate visual information directly into eyeglass lenses, a development that just might be able to make display technologies like Google Glass less like Google Glass.\n\nThe VTT-developed technology uses millimeter-thick elements to guide light through glass or plastic. While maintaining excellent transparency, the high-tech display can project a high quality image\u2014equal to that of watching a 60-inch TV from 3 meters away\u2014directly yet unobtrusively into a user\u2019s field of vision. The tech is being commercialized by spin-off company Dispelix Oy.\n\n\u201cCompared to existing solutions, which are bulky or difficult to manufacture, the Dispelix solution has advantages such as the display\u2019s thinness, lightness, aesthetic appearance and volume production compatibility,\u201d says Antti Sunnari, managing director of Dispelix Oy.\n\n1120ctt glass piece lo res\n\nAntti Sunnari, managing director of Dispelix Oy, holds a demonstration of the company\u2019s glass technology. Credit: Juha Sarkkinen; VTT\n\n1120ctt lightguide lo res\n\nClose-up shows the display within a piece of glass. Credit: Juha Sarkkinen; VTT\n\nThe display can be freely shaped and configured depending on the application, including monochrome or multicolored displays, making it useful for a host of potential applications and configurations.\n\nAccording to a VTT press release, the display will first find its way into exercise, work, and motor sport applications. \u201cThanks to the new display, a sportsperson will no longer need to check his or her pulse-rate from a watch\u2014pulse-rate, navigation and activity data will be directly displayed on sport glasses.\u201d\n\nThe team thinks its tech will also be useful in professional settings, where it could potentially \u201cboost work efficiency by allowing workers to use both hands in difficult conditions, or to learn more about the task as the work progresses.\u201d\n\nThe company is now fundraising and networking with other companies and partners, according to the release. \u201cThe displays are ready for volume production and the company aims to make the first customer deliveries in 2016.\u201d",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9701598883,
        "format_confidence":0.6619467139
    },
    {
        "url":"http:\/\/itknowledgeexchange.techtarget.com\/total-cio\/the-dirty-little-secret-of-data-center-construction\/",
        "text":"Apr 29 2011 \u00a0 11:54AM GMT\n\nThe dirty little secret of data center construction\n\n4Laura Laura Smith Profile: 4Laura\n\nMuch of the data center construction around the globe is being conducted by purveyors of popular websites like Facebook and Google. These heroes of the Information Age are feverishly expanding capacity to deal with the massive amount of data being generated by their services over the Internet.\n\nBut look behind the curtain, and these Wizards of Oz have a dirty little secret: To a staggering degree, they\u2019re still buying electricity generated by coal-burning power plants.\n\n\u201cThe IT industry\u2019s failure to disclose basic information on its rapidly growing energy footprint has hidden a continued reliance on 19th-century dirty coal power to power its 21st-century infrastructure,\u201d said Gary Cook, an IT policy analyst at Greenpeace International, an Amsterdam-based organization that uses nonviolent, creative confrontation to expose global environmental problems.\n\nApple, Facebook and IBM have the biggest appetites for coal-generated electricity, consuming enough to supply more than half of their power needs, according to a new report from Greenpeace titled, \u201cHow Dirty is Your Data?\u201d.\n\nThe report analyzes publicly available information to estimate the amount of clean and dirty energy being driven by investment decisions and energy choices by the major Internet brands. Finding those numbers from within the companies proved nearly impossible, according to Cook.\n\n\u201cDespite the fact that data centers \u2026 currently consume 1.5% to 2% of all global electricity and are growing at a rate of 12% per year, companies in the sector as a whole do not release information on their energy use and its associated global warming emissions,\u201d Cook wrote.\n\nU.S. data center construction is clustering in places like North Carolina and the Midwest, where cheap, coal-powered electricity is abundant. When opened, the Apple iData Center in North Carolina, for example, will consume an estimated 100 megawatts \u2014 equivalent to the electricity needed to power about 80,000 U.S. homes, or a quarter-million European Union ones. Apple has not yet announced how the data center will be powered.\n\nGreenpeace\u2019s estimates of coal intensity put IBM, HP and Twitter just behind Apple and Facebook: Apple at 54.5%, Facebook at 53.2%, IBM at 51.6%, HP at 49.4% and Twitter at 42.5%. Google\u2019s coal intensity is ranked at 34.7%, Microsoft\u2019s at 34.1%, Amazon\u2019s at 28.5% and Yahoo\u2019s at 18.3%.\n\nRecognizing that such IT giants could be the group that leads the world to renewable energy \u2014 or, conversely, hastens the adverse effects of global warming \u2014 Greenpeace this month issued an Earth Day challenge to Facebook, calling upon the company to \u201cunfriend coal.\u201d\n\nAlas, the deadline came and went with no such action, despite a blizzard of posts from 700,000 Greenpeace supporters who set a Guinness World Record for the most comments on a Facebook post in 24 hours.\n\nGoogle, at least, is getting the message when it comes to new data center construction. The Mountain View, Calif.-based company announced last week that it would purchase power for the next 20 years from a wind farm to be built in Oklahoma; this follows a similar agreement last year to buy power from a wind farm in Ohio. Google plans to sell surplus energy from the farms to the local electrical grid, thereby ensuring that more renewable energy enters the market as part of Google\u2019s goal of operating on a carbon-neutral footprint.\n\nCoal-burning power plants emit harmful chemicals that are warming the Earth\u2019s atmosphere to life-threatening levels. Nuclear power, long proposed as the safe alternative, is explosive under certain circumstances, as we\u2019ve seen at Japan\u2019s Fukushima Daiichi plant. Moreover, it\u2019s extremely difficult to safely store spent fuel rods.\n\nWind, solar and geothermal power projects are coming along, but not as fast as the rate of data, which is forcing huge cloud providers to choose power sources during data center construction that appear to be less costly. Yet these business practices could be costly for environmental health, which affects us all.\n\n1 \u00a0Comment on this Post\n\nThere was an error processing your information. Please try again later.\nThanks. We'll let you know when a new response is added.\nSend me notifications when other members comment.\n\nREGISTER or login:\n\nForgot Password?\nBy submitting you agree to receive email from TechTarget and its partners. If you reside outside of the United States, you consent to having your personal data transferred to and processed in the United States. Privacy\n  \u2022 SamplerPG\n    Unfortunately, Greenpeace's usual propaganda emanating from their Holland offices which receives most of it's power from Frances 80% nuclear power based infrastrutcure. The hypothesis of dangerous runaway man made global warming is false, and designed by a politically minded, anti-capitalist group, with support from self interest groups requiring bottomless pits of money from taxpayers to research their pet interests, and using fear to scare the general public and politicians. Prior to coal fired power stations, there were notable periods in the earth's history where atmospheric concentrations of carbon dioxide, not a pollutant, but an intrinsic part of the world's ecosystem food chain, were far higher than the worst projections being bandied about by Greenpeace scaremongers, and there was NO RUNAWAY DANGEROUS GLOBAL WARMING. How terribly inconvenient. Modern coal burning plants have made huge strides in cleaning up real pollutants like sulphur dioxide and particulate matter from their stacks, but all these positive moves pale into insignificance when measured against sulphur and particulate matter blasted out by inconvenient, non UNO and Greenpeace regulated volcanoes, both above, and below the sea. And is that really bad? Only recently have deep-sea cameras provided stunning and completely unexpected evidence of abundant life forms apparently thriving in high sulphur and very high temperatures around the vents of these sub-marine cative volcanoes. The notion that man can really influence the world's intricate climate system whilst driven by an uncontrollable atomic power station in the sky is just plain silly. Yet every generation's scientists like to think that they are the ones with the full understanding of nature, and the ones before them were jsut uninformed. This generation's whose scientists promote the fear of dangerous runaway global warming for monetary gain and research grants will be mocked by their successors in the very near future. But unlike their forebears, this new generation of scaremongers is making excellent money out of the scam, and they won't be around to be brought to task when their Madoff like adventure is eventually proved completely silly. But the taxes will have been taken and enjoyed! In true scientific debate, anyone claiming that dissent or alternative viewpoints should be shut down, clearly represents the same idiology expressed in the past, where for instance a medical doctor suggested washing hands before an operation would increase the chances of a successful outcome. He was ridiculed and pilloried by the mainstream medical groups of the time, just like the IPCC and Greenpeace do today to anyone who doesn't share their agenda. That's how you know who they really are. When so called scientiests have to fiddle the data using various \"tricks\" to hide the cooling, then you know what a scam it has become.\n    0 pointsBadges:\n\nForgot Password\n\nNo problem! Submit your e-mail address below. We'll send you an e-mail containing your password.\n\nYour password has been sent to:\n\nShare this item with your network:",
        "topic_id":19,
        "format_id":11,
        "topic_confidence":0.9608737826,
        "format_confidence":0.8618620038
    }
]